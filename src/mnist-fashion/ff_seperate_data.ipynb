{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/kemalty/feed-forward-n-n-with-keras-for-fashion-mnist/notebook?select=fashion-mnist_train.csv\n",
    "\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Loading and pre-processing training dataset\n",
    "train_data = pd.read_csv(\"data/fashion-mnist_train.csv\")\n",
    "train_data_a = train_data.loc[train_data.label>=5]\n",
    "train_data_b = train_data.loc[train_data.label<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.DataFrame(train_data[[\"label\"]].copy(deep=False)) # Seperate labels (y) from inputs (X)\n",
    "train_label_a = pd.DataFrame(train_data_a[[\"label\"]].copy(deep=False)) - 5\n",
    "train_label_b = pd.DataFrame(train_data_b[[\"label\"]].copy(deep=False))\n",
    "\n",
    "train_input = pd.DataFrame(train_data.drop(\"label\", 1, inplace=False))\n",
    "train_input_a = pd.DataFrame(train_data_a.drop(\"label\", 1, inplace=False))\n",
    "train_input_b = pd.DataFrame(train_data_b.drop(\"label\", 1, inplace=False))\n",
    "del train_data\n",
    "del train_data_a\n",
    "del train_data_b\n",
    "\n",
    "# Convert labels to dummies (one-hot encoding) so that they can be used in the output layer\n",
    "train_label = to_categorical(train_label)\n",
    "train_label_a = to_categorical(train_label_a)\n",
    "train_label_b = to_categorical(train_label_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means:\n",
      "pixel1    0.000900\n",
      "pixel2    0.006150\n",
      "pixel3    0.035333\n",
      "pixel4    0.101933\n",
      "pixel5    0.247967\n",
      "dtype: float64\n",
      "pixel1    0.000867\n",
      "pixel2    0.007167\n",
      "pixel3    0.031600\n",
      "pixel4    0.109067\n",
      "pixel5    0.265300\n",
      "dtype: float64\n",
      "pixel1    0.000933\n",
      "pixel2    0.005133\n",
      "pixel3    0.039067\n",
      "pixel4    0.094800\n",
      "pixel5    0.230633\n",
      "dtype: float64\n",
      "Stds:\n",
      "pixel1    0.094689\n",
      "pixel2    0.271011\n",
      "pixel3    1.222324\n",
      "pixel4    2.452871\n",
      "pixel5    4.306912\n",
      "dtype: float64\n",
      "pixel1    0.084850\n",
      "pixel2    0.348022\n",
      "pixel3    1.588842\n",
      "pixel4    2.963961\n",
      "pixel5    5.029310\n",
      "dtype: float64\n",
      "pixel1    0.103599\n",
      "pixel2    0.160544\n",
      "pixel3    0.680996\n",
      "pixel4    1.802273\n",
      "pixel5    3.435846\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Normalize the inputs\n",
    "train_means = train_input.mean(axis=0) # Keep these for test too\n",
    "train_means_a = train_input_a.mean(axis=0) # Keep these for test too\n",
    "train_means_b = train_input_b.mean(axis=0) # Keep these for test too\n",
    "\n",
    "train_stds  = train_input.std(axis=0)\n",
    "train_stds_a  = train_input_a.std(axis=0)\n",
    "train_stds_b  = train_input_b.std(axis=0)\n",
    "\n",
    "print(\"Means:\")\n",
    "print(train_means.head(5))\n",
    "print(train_means_a.head(5))\n",
    "print(train_means_b.head(5))\n",
    "print(\"Stds:\")\n",
    "print(train_stds.head(5))\n",
    "print(train_stds_a.head(5))\n",
    "print(train_stds_b.head(5))\n",
    "\n",
    "train_input = train_input - train_means # Zero mean\n",
    "train_input_a = train_input_a - train_means_a # Zero mean\n",
    "train_input_b = train_input_b - train_means_b # Zero mean\n",
    "\n",
    "train_input = train_input / train_stds # 1 standard deviation\n",
    "train_input_a = train_input_a / train_stds_a # 1 standard deviation\n",
    "train_input_b = train_input_b / train_stds_b # 1 standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0             1             2             3             4  \\\n",
      "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
      "mean       0.100000      0.100000      0.100000      0.100000      0.100000   \n",
      "std        0.300024      0.300024      0.300024      0.300025      0.300024   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "                  5             6             7             8             9  \n",
      "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000  \n",
      "mean       0.100000      0.100000      0.100000      0.100000      0.100000  \n",
      "std        0.300024      0.300024      0.300024      0.300024      0.300024  \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Loading and pre-processing testing dataset\n",
    "test_data = pd.read_csv(\"data/fashion-mnist_test.csv\") # Load the csv from file\n",
    "test_data_a = test_data.loc[test_data.label>=5]\n",
    "test_data_b = test_data.loc[test_data.label<5]\n",
    "\n",
    "test_label = pd.DataFrame(test_data[[\"label\"]].copy(deep=False)) # Seperate labels (y) from inputs (X)\n",
    "test_label_a = pd.DataFrame(test_data_a[[\"label\"]].copy(deep=False)) - 5 # Seperate labels (y) from inputs (X)\n",
    "test_label_b = pd.DataFrame(test_data_b[[\"label\"]].copy(deep=False)) # Seperate labels (y) from inputs (X)\n",
    "\n",
    "test_input = pd.DataFrame(test_data.drop(\"label\", 1, inplace=False))\n",
    "test_input_a = pd.DataFrame(test_data_a.drop(\"label\", 1, inplace=False))\n",
    "test_input_b = pd.DataFrame(test_data_b.drop(\"label\", 1, inplace=False))\n",
    "\n",
    "del test_data\n",
    "del test_data_a\n",
    "del test_data_b\n",
    "\n",
    "# Convert labels to dummies (one-hot encoding) so that they can be used in the output layer\n",
    "test_label = to_categorical(test_label)\n",
    "test_label_a = to_categorical(test_label_a)\n",
    "test_label_b = to_categorical(test_label_b)\n",
    "\n",
    "print(pd.DataFrame(test_label).describe())\n",
    "\n",
    "# Apply normalization\n",
    "test_input = test_input - train_means # Zero mean\n",
    "test_input = test_input / train_stds # 1 standard deviation\n",
    "test_input_a = test_input_a - train_means_a # Zero mean\n",
    "test_input_a = test_input_a / train_stds_a # 1 standard deviation\n",
    "test_input_b = test_input_b - train_means_b # Zero mean\n",
    "test_input_b = test_input_b / train_stds_b # 1 standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 130       \n",
      "=================================================================\n",
      "Total params: 629,555\n",
      "Trainable params: 629,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Set-up the network\n",
    "model = Sequential()\n",
    "model.add(Dense(units=500, input_dim=train_input.shape[1],\n",
    "                activation=\"relu\",\n",
    "                 kernel_initializer=\"random_uniform\",\n",
    "                 bias_initializer=\"zeros\"))\n",
    "model.add(Dropout(0.30))\n",
    "model.add(Dense(units=300, activation=\"relu\", kernel_initializer=\"random_uniform\", bias_initializer=\"zeros\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units=200, activation=\"relu\", kernel_initializer=\"random_uniform\", bias_initializer=\"zeros\"))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(units=100, activation=\"relu\", kernel_initializer=\"random_uniform\", bias_initializer=\"zeros\"))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(units=50, activation=\"relu\", kernel_initializer=\"random_uniform\", bias_initializer=\"zeros\"))\n",
    "model.add(Dropout(0.10))\n",
    "model.add(Dense(units=25, activation=\"relu\", kernel_initializer=\"random_uniform\", bias_initializer=\"zeros\"))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(units=5, activation=\"softmax\"))\n",
    "\n",
    "# Print out the network configuration\n",
    "print(model.summary())\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_train = train_input.to_numpy()\n",
    "y_train = train_label\n",
    "\n",
    "X_train_d = [train_input_a.to_numpy(), train_input_b.to_numpy()]\n",
    "y_train_d = [train_label_a, train_label_b]\n",
    "\n",
    "X_test_d = [test_input_a.to_numpy(), test_input_b.to_numpy()]\n",
    "y_test_d = [test_label_a, test_label_b]\n",
    "\n",
    "og_file_name = 'models/main_ff_sep.h5'\n",
    "model.save(og_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model - 0\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 1.4696 - accuracy: 0.3717\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.9686 - accuracy: 0.6071\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.6707 - accuracy: 0.8056\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.4794 - accuracy: 0.8496\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3312 - accuracy: 0.8911\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.3779 - accuracy: 0.8785\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.2717 - accuracy: 0.9100\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.3150 - accuracy: 0.8967\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2891 - accuracy: 0.9094\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2305 - accuracy: 0.9261\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.2531 - accuracy: 0.9182\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2354 - accuracy: 0.9266\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.2398 - accuracy: 0.9277\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2004 - accuracy: 0.9380\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.2156 - accuracy: 0.9329\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.1805 - accuracy: 0.9446\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.2088 - accuracy: 0.9341\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.1996 - accuracy: 0.9407\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.1678 - accuracy: 0.9486\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.2016 - accuracy: 0.9375\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.9398\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1445 - accuracy: 0.9540\n",
      "\n",
      "Test Accuracy:0.9398000240325928\n",
      "Train Accuracy:0.9539666771888733\n",
      "Training model - 1\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 1.5491 - accuracy: 0.3169\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 1.0956 - accuracy: 0.5315\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.8238 - accuracy: 0.6062\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.7444 - accuracy: 0.6502\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.6169 - accuracy: 0.7395\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.5365 - accuracy: 0.7910\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.5229 - accuracy: 0.7955\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.4899 - accuracy: 0.8182\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.4348 - accuracy: 0.8470\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.4291 - accuracy: 0.8496\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.4176 - accuracy: 0.8549\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.4279 - accuracy: 0.8518\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.3773 - accuracy: 0.8721\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.3991 - accuracy: 0.8638\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.3588 - accuracy: 0.8777\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.3741 - accuracy: 0.8713\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.3570 - accuracy: 0.8789\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.3472 - accuracy: 0.8810\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.3434 - accuracy: 0.8820\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.3295 - accuracy: 0.8887\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.8750\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3360 - accuracy: 0.8764\n",
      "\n",
      "Test Accuracy:0.875\n",
      "Train Accuracy:0.8764333128929138\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "import keras\n",
    "\n",
    "for i in range(2):\n",
    "    print(\"Training model - {}\".format(i))\n",
    "    \n",
    "    model_train_data = X_train_d[i]\n",
    "    model_train_labels = y_train_d[i]\n",
    "\n",
    "    model = keras.models.load_model(og_file_name)\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=\"RMSprop\",#lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(model_train_data, model_train_labels, epochs=20, batch_size=6000)\n",
    "    \n",
    "    model_name = \"models/model_ff_sep_{}.h5\".format(i)\n",
    "    model.save(model_name)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss_and_metrics = model.evaluate(X_test_d[i], y_test_d[i])\n",
    "    train_loss_and_metrics = model.evaluate(model_train_data, model_train_labels)\n",
    "    print(\"\")\n",
    "    print(\"Test Accuracy:\" + str(test_loss_and_metrics[1]))\n",
    "    print(\"Train Accuracy:\" + str(train_loss_and_metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def split(array, nrows, ncols):\n",
    "    \"\"\"Split a matrix into sub-matrices.\"\"\"\n",
    "    r, h = array.shape\n",
    "    if r % nrows != 0:\n",
    "        padding = (math.ceil(r / nrows) * nrows) - r\n",
    "        array = np.vstack((array, np.zeros((padding, h))))\n",
    "        r, h = array.shape\n",
    "    if h % ncols != 0:\n",
    "        padding = (math.ceil(h / ncols) * ncols) - h\n",
    "        array = np.hstack((array, np.zeros((r, padding))))\n",
    "        r, h = array.shape\n",
    "#     print(array.shape)\n",
    "    num_x_blocks = math.ceil(r / float(nrows))\n",
    "    num_y_blocks = math.ceil(h / float(ncols))\n",
    "    \n",
    "    rows = np.vsplit(array, num_x_blocks)\n",
    "    return [np.array(np.hsplit(row, num_y_blocks)) for row in rows]  \n",
    "#     chunks = array.reshape(h//nrows, nrows, -1, ncols).swapaxes(1, 2).reshape(-1, nrows, ncols)\n",
    "#     return np.split(chunks, num_x_blocks)\n",
    "\n",
    "def gather_blocks_to_pages(splits, num_elem_per_page):\n",
    "    blocks = np.concatenate(splits)\n",
    "    pages = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(blocks):\n",
    "        count = 0\n",
    "        page = []\n",
    "        while i < len(blocks) and count + blocks[i].shape[0] * blocks[i].shape[1] <= num_elem_per_page:\n",
    "            page.append(blocks[i])\n",
    "            count += blocks[i].shape[0] * blocks[i].shape[1]\n",
    "            i += 1\n",
    "        pages.append(page)\n",
    "        print(\"Adding {} elems to page {}\".format(count, len(pages) - 1))\n",
    "    return pages\n",
    "\n",
    "# So we assume that if one page as lesser blocks than the other,\n",
    "# We should see if the smaller one matches the bigger one from\n",
    "# the start, and not anywhere in between\n",
    "def page_similarity(ps1, ps2):\n",
    "    sim = np.zeros((len(ps1), len(ps2)))\n",
    "    \n",
    "    for i, p1 in enumerate(ps1):\n",
    "        for j, p2 in enumerate(ps2):\n",
    "            k = min(len(p1), len(p2))\n",
    "            a = np.array(p1[:k])\n",
    "            b = np.array(p2[:k])\n",
    "            c = np.count_nonzero(np.absolute(a - b) <= 0.01)\n",
    "            sim[i][j] = c / a.size\n",
    "    \n",
    "    return sim\n",
    "            \n",
    "\n",
    "def merge_blocks(blocks, num_blocks_x, num_blocks_y, x, y):\n",
    "    b_x, b_y = blocks[0].shape\n",
    "    t_x, t_y = (b_x * num_blocks_x, b_y * num_blocks_y,)\n",
    "    rows = [np.hstack(blocks[i*num_blocks_y:i*num_blocks_y+num_blocks_y]) for i in range(num_blocks_x)]\n",
    "    matrix = np.vstack(rows)\n",
    "    assert matrix.shape[0] == t_x\n",
    "    r_x = t_x - x\n",
    "    r_y = t_y - y\n",
    "    if r_x == 0 and r_y == 0:\n",
    "        return matrix\n",
    "    elif r_x == 0:\n",
    "        return matrix[:,:-r_y]\n",
    "    elif r_y == 0:\n",
    "        return matrix[:-r_x,:]\n",
    "    else:\n",
    "        return matrix[:-r_x, :-r_y]\n",
    "\n",
    "# merge_blocks(x, 2, 2, 4, 4)\n",
    "# x[0]\n",
    "\n",
    "def pages_to_blocks(pages):\n",
    "    blocks = []\n",
    "    for p in pages:\n",
    "        blocks.extend(p)\n",
    "    return blocks\n",
    "\n",
    "def merge_pages(p1, p2):\n",
    "    ps = []\n",
    "    for i, p in enumerate(p1):\n",
    "        if i >= len(p2):\n",
    "            ps.append(np.array(p))\n",
    "        else:\n",
    "            ps.append((p + p2[i]) / 2)\n",
    "    return ps\n",
    "\n",
    "def combine_similar_pages(ps1, ps2, sim_scores, threshold=0.9):\n",
    "    new_ps1 = [None] * len(ps1)\n",
    "    new_ps2 = [None] * len(ps2)\n",
    "    \n",
    "    for ps1_idx, scores in enumerate(sim_scores):\n",
    "        if np.max(scores) >= threshold:\n",
    "            ps2_idx = np.argmax(scores)\n",
    "            print(\"PS1: Merging {} and {}\".format(ps1_idx, ps2_idx))\n",
    "            new_ps1[ps1_idx] = merge_pages(ps1[ps1_idx], ps2[ps2_idx])\n",
    "            new_ps2[ps2_idx] = ps1_idx\n",
    "        else:\n",
    "            # No need to make new copies here since we should not be using ps1 or ps2 anymore\n",
    "            new_ps1[ps1_idx] = ps1[ps1_idx]\n",
    "\n",
    "    for ps2_idx in range(len(ps2)):\n",
    "        if new_ps2[ps2_idx] is not None:\n",
    "            ps1_idx = new_ps2[ps2_idx]\n",
    "            print(\"PS2: Merging {} and {}\".format(ps2_idx, ps1_idx))\n",
    "            new_ps2[ps2_idx] = merge_pages(ps2[ps2_idx], ps1[ps1_idx])\n",
    "        else:\n",
    "            # No need to make new copies here since we should not be using ps1 or ps2 anymore\n",
    "            new_ps2[ps2_idx] = ps2[ps2_idx]\n",
    "\n",
    "    return new_ps1, new_ps2\n",
    "\n",
    "def weight_sim(w1, w2):\n",
    "    nw1 = w1.flatten()\n",
    "    nw2 = w2.flatten()\n",
    "    if nw1.size < nw2.size:\n",
    "        rem = nw2.size - nw1.size\n",
    "        nw2 = nw2[:-rem]\n",
    "    elif nw1.size > nw2.size:\n",
    "        rem = nw1.size - nw2.size\n",
    "        nw1 = nw1[:-rem]\n",
    "        \n",
    "    return np.count_nonzero(np.absolute(nw2 - nw1) <= 0.01) / nw1.size\n",
    "\n",
    "def share_weights(w1, w2, a, b, c, t):\n",
    "    m, n = w1.shape\n",
    "    x = split(w1, a, b)\n",
    "    bx, by = len(x), x[0].shape[0]\n",
    "\n",
    "    o, p = w2.shape\n",
    "    y = split(w2, a, b)\n",
    "    cx, cy = len(y), y[0].shape[0]\n",
    "    \n",
    "    ps1 = gather_blocks_to_pages(x, c) # ~1MB 16 bytes * 63725\n",
    "    ps2 = gather_blocks_to_pages(y, c) # ~1MB 16 bytes * 63725\n",
    "\n",
    "    sim = page_similarity(ps1, ps2)\n",
    "    print(sim)\n",
    "    \n",
    "    nps1, nps2 = combine_similar_pages(ps1, ps2, sim, t)\n",
    "    \n",
    "    wb1 = pages_to_blocks(nps1)\n",
    "    wb1 = merge_blocks(wb1, bx, by, m, n)\n",
    "    \n",
    "    wb2 = pages_to_blocks(nps2)\n",
    "    wb2 = merge_blocks(wb2, cx, cy, o, p)\n",
    "    \n",
    "    return wb1, wb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.models.load_model('models/model_ff_sep_0.h5')\n",
    "model2 = keras.models.load_model('models/model_ff_sep_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 65525 elems to page 0\n",
      "Adding 65525 elems to page 1\n",
      "Adding 65525 elems to page 2\n",
      "Adding 65525 elems to page 3\n",
      "Adding 65525 elems to page 4\n",
      "Adding 64875 elems to page 5\n",
      "Adding 65525 elems to page 0\n",
      "Adding 65525 elems to page 1\n",
      "Adding 65525 elems to page 2\n",
      "Adding 65525 elems to page 3\n",
      "Adding 65525 elems to page 4\n",
      "Adding 64875 elems to page 5\n",
      "[[0.37448302 0.16602823 0.16613506 0.16843953 0.16495994 0.16262042]\n",
      " [0.16144983 0.40724914 0.16630294 0.16848531 0.164029   0.16359152]\n",
      " [0.15862648 0.15977108 0.36601297 0.16433422 0.16204502 0.1597842 ]\n",
      " [0.15754292 0.16152614 0.16158718 0.38771461 0.16172453 0.15964547]\n",
      " [0.15964899 0.168409   0.16547882 0.16538726 0.40671499 0.16326782]\n",
      " [0.16211175 0.17174566 0.17097495 0.17114451 0.16941811 0.42577264]]\n",
      "PS1: Merging 1 and 1\n",
      "PS1: Merging 4 and 4\n",
      "PS1: Merging 5 and 5\n",
      "PS2: Merging 1 and 1\n",
      "PS2: Merging 4 and 4\n",
      "PS2: Merging 5 and 5\n"
     ]
    }
   ],
   "source": [
    "w1, b1 = model1.layers[0].get_weights()\n",
    "w2, b2 = model2.layers[0].get_weights()\n",
    "\n",
    "w1, w2 = share_weights(w1, w2, 5, 5, 65536, 0.4) #63725\n",
    "\n",
    "model1.layers[0].set_weights([w1, b1])\n",
    "model2.layers[0].set_weights([w2, b2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 63725 elems to page 0\n",
      "Adding 63725 elems to page 1\n",
      "Adding 22550 elems to page 2\n",
      "Adding 63725 elems to page 0\n",
      "Adding 63725 elems to page 1\n",
      "Adding 22550 elems to page 2\n",
      "[[0.3684896  0.15949784 0.16359202]\n",
      " [0.1583523  0.37220871 0.15968958]\n",
      " [0.15782705 0.16013304 0.37654102]]\n",
      "PS1: Merging 0 and 0\n",
      "PS1: Merging 1 and 1\n",
      "PS1: Merging 2 and 2\n",
      "PS2: Merging 0 and 0\n",
      "PS2: Merging 1 and 1\n",
      "PS2: Merging 2 and 2\n"
     ]
    }
   ],
   "source": [
    "w1, b1 = model1.layers[2].get_weights()\n",
    "w2, b2 = model2.layers[2].get_weights()\n",
    "\n",
    "w1, w2 = share_weights(w1, w2, 5, 5, 63725, 0.3) #63725\n",
    "\n",
    "model1.layers[2].set_weights([w1, b1])\n",
    "model2.layers[2].set_weights([w2, b2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 16375 elems to page 0\n",
      "Adding 16375 elems to page 1\n",
      "Adding 16375 elems to page 2\n",
      "Adding 10875 elems to page 3\n",
      "Adding 16375 elems to page 0\n",
      "Adding 16375 elems to page 1\n",
      "Adding 16375 elems to page 2\n",
      "Adding 10875 elems to page 3\n",
      "[[0.42564885 0.15865649 0.16134351 0.15926437]\n",
      " [0.16238168 0.39767939 0.16042748 0.16073563]\n",
      " [0.16916031 0.16598473 0.39737405 0.16551724]\n",
      " [0.15577011 0.16726437 0.15944828 0.40248276]]\n",
      "PS1: Merging 0 and 0\n",
      "PS1: Merging 3 and 3\n",
      "PS2: Merging 0 and 0\n",
      "PS2: Merging 3 and 3\n"
     ]
    }
   ],
   "source": [
    "w1, b1 = model1.layers[4].get_weights()\n",
    "w2, b2 = model2.layers[4].get_weights()\n",
    "\n",
    "w1, w2 = share_weights(w1, w2, 5, 5, 16384, 0.4) #63725\n",
    "\n",
    "model1.layers[4].set_weights([w1, b1])\n",
    "model2.layers[4].set_weights([w2, b2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 8175 elems to page 0\n",
      "Adding 8175 elems to page 1\n",
      "Adding 3650 elems to page 2\n",
      "Adding 8175 elems to page 0\n",
      "Adding 8175 elems to page 1\n",
      "Adding 3650 elems to page 2\n",
      "[[0.43045872 0.16318043 0.16958904]\n",
      " [0.16061162 0.41590214 0.14794521]\n",
      " [0.16027397 0.16931507 0.41616438]]\n",
      "PS1: Merging 0 and 0\n",
      "PS1: Merging 1 and 1\n",
      "PS1: Merging 2 and 2\n",
      "PS2: Merging 0 and 0\n",
      "PS2: Merging 1 and 1\n",
      "PS2: Merging 2 and 2\n"
     ]
    }
   ],
   "source": [
    "w1, b1 = model1.layers[6].get_weights()\n",
    "w2, b2 = model2.layers[6].get_weights()\n",
    "\n",
    "w1, w2 = share_weights(w1, w2, 5, 5, 8192, 0.4) #63725\n",
    "\n",
    "model1.layers[6].set_weights([w1, b1])\n",
    "model2.layers[6].set_weights([w2, b2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3852 - accuracy: 0.9304\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.3698 - accuracy: 0.9439\n",
      "\n",
      "Test Accuracy:0.930400013923645\n",
      "Train Accuracy:0.9439333081245422\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.8710\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.5792 - accuracy: 0.8655\n",
      "\n",
      "Test Accuracy:0.8709999918937683\n",
      "Train Accuracy:0.8655333518981934\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss_and_metrics = model1.evaluate(X_test_d[0], y_test_d[0])\n",
    "train_loss_and_metrics = model1.evaluate(X_train_d[0], y_train_d[0])\n",
    "print(\"\")\n",
    "print(\"Test Accuracy:\" + str(test_loss_and_metrics[1]))\n",
    "print(\"Train Accuracy:\" + str(train_loss_and_metrics[1]))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss_and_metrics = model2.evaluate(X_test_d[1], y_test_d[1])\n",
    "train_loss_and_metrics = model2.evaluate(X_train_d[1], y_train_d[1])\n",
    "print(\"\")\n",
    "print(\"Test Accuracy:\" + str(test_loss_and_metrics[1]))\n",
    "print(\"Train Accuracy:\" + str(train_loss_and_metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def fisher(model, raw_data):\n",
    "    y = model.output\n",
    "\n",
    "    row_idx = tf.range(tf.shape(y)[0])\n",
    "    col_idx = tf.argmax(y, axis=1, output_type=tf.dtypes.int32)\n",
    "    full_indices = tf.stack([row_idx, col_idx], axis=1)\n",
    "    fx_tensors = tf.gather_nd(y, full_indices)\n",
    "\n",
    "    x_tensors = model.trainable_weights\n",
    "\n",
    "    num_samples = 100\n",
    "    m = Model(inputs=model.input, outputs=fx_tensors)\n",
    "\n",
    "    fisher_information = []\n",
    "    for v in range(len(x_tensors)):\n",
    "        fisher_information.append(np.zeros(x_tensors[v].get_shape().as_list()).astype(np.float32))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        data_idx = np.random.randint(raw_data.shape[0])\n",
    "        sampled_data = raw_data[data_idx:data_idx+1]\n",
    "        sampled_input_variables = [ sampled_data ]\n",
    "#         print ('sample num: %4d, data_idx: %5d' % (i, data_idx))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            p = m(sampled_data)\n",
    "            lo = tf.math.log(p)\n",
    "\n",
    "        gradients = tape.gradient(lo, x_tensors)\n",
    "        derivatives = [g.numpy() for g in gradients]\n",
    "        prob = p.numpy()[0]\n",
    "\n",
    "    #     derivatives, prob = sess.run([tf.gradients(tf.log(fx_tensors), x_tensors), fx_tensors],\n",
    "    #     feed_dict={t: v for t,v in zip(input_tensors, sampled_input_variables)})\n",
    "\n",
    "        for v in range(len(fisher_information)):\n",
    "            fisher_information[v] += np.square(derivatives[v]) * prob\n",
    "\n",
    "    for v in range(len(fisher_information)):\n",
    "        fisher_information[v] /= num_samples\n",
    "    \n",
    "    return fisher_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.models.load_model('models/model_ff_sep_0.h5')\n",
    "model2 = keras.models.load_model('models/model_ff_sep_1.h5')\n",
    "\n",
    "model_train_data = X_train_d[0]\n",
    "model_train_labels = y_train_d[0]\n",
    "\n",
    "fi1 = fisher(model1, model_train_data)\n",
    "\n",
    "model_train_data = X_train_d[1]\n",
    "model_train_labels = y_train_d[1]\n",
    "\n",
    "fi2 = fisher(model2, model_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# if using a Jupyter notebook, include:\n",
    "%matplotlib inline\n",
    "\n",
    "kk = [0, 2, 4, 6]\n",
    "\n",
    "d = [x.flatten() for i, x in enumerate(fi1) if i in kk]\n",
    "d = np.concatenate(d)\n",
    "\n",
    "# d = a[0].flatten()\n",
    "# index = np.arange(len(d))\n",
    "# plt.bar(index, d)\n",
    "plt.plot(d)\n",
    "plt.ylabel('fisher importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kk = [0, 2, 4, 6]\n",
    "\n",
    "d = [x.flatten() for i, x in enumerate(fi2) if i in kk]\n",
    "d = np.concatenate(d)\n",
    "\n",
    "# d = a[0].flatten()\n",
    "# index = np.arange(len(d))\n",
    "# plt.bar(index, d)\n",
    "plt.plot(d)\n",
    "plt.ylabel('fisher importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
