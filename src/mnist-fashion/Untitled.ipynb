{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/shivamb/how-autoencoders-work-intro-and-usecases/data#2.1-UseCase-1-:-Image-Reconstruction\n",
    "## load the libraries \n",
    "from keras.layers import Dense, Input, Conv2D, LSTM, MaxPool2D, UpSampling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from numpy import argmax, array_equal\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from imgaug import augmenters\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read dataset \n",
    "train = pd.read_csv(\"data/fashion-mnist_train.csv\")\n",
    "train_x = train[list(train.columns)[1:]].values\n",
    "train_y = train['label'].values\n",
    "\n",
    "## normalize and reshape the predictors  \n",
    "train_x = train_x / 255\n",
    "\n",
    "## create train and validation datasets\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2)\n",
    "\n",
    "## reshape the inputs\n",
    "train_x = train_x.reshape(-1, 784)\n",
    "val_x = val_x.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input layer\n",
    "input_layer = Input(shape=(784,))\n",
    "\n",
    "## encoding architecture\n",
    "encode_layer1 = Dense(1500, activation='relu')(input_layer)\n",
    "encode_layer2 = Dense(1000, activation='relu')(encode_layer1)\n",
    "encode_layer3 = Dense(500, activation='relu')(encode_layer2)\n",
    "\n",
    "## latent view\n",
    "latent_view   = Dense(10, activation='sigmoid')(encode_layer3)\n",
    "\n",
    "## decoding architecture\n",
    "decode_layer1 = Dense(500, activation='relu')(latent_view)\n",
    "decode_layer2 = Dense(1000, activation='relu')(decode_layer1)\n",
    "decode_layer3 = Dense(1500, activation='relu')(decode_layer2)\n",
    "\n",
    "## output layer\n",
    "output_layer  = Dense(784)(decode_layer3)\n",
    "\n",
    "model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1500)              1177500   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              1501000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               5500      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1000)              501000    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1500)              1501500   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 784)               1176784   \n",
      "=================================================================\n",
      "Total params: 6,368,794\n",
      "Trainable params: 6,368,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_percent = 75 / 100\n",
    "shared_train_data_size = int(len(train_x) * shared_percent)\n",
    "num_models = 2\n",
    "\n",
    "shared_train_data = train_x[:shared_train_data_size]\n",
    "shared_train_labels = val_x[:shared_train_data_size]\n",
    "private_train_data = np.split(train_x[shared_train_data_size:], num_models)\n",
    "private_train_labels = np.split(\n",
    "    val_x[shared_train_data_size:], num_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(model, prefix):\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if len(layer.get_weights()) == 0:\n",
    "            continue\n",
    "        m = layer.get_weights()\n",
    "        np.savetxt('weights/{}-w{}.out'.format(prefix, i), m[0], header=\"{},{}\".format(*m[0].shape), delimiter=\",\")\n",
    "        np.savetxt('weights/{}-b{}.out'.format(prefix, i), m[1], header=\"{},{}\".format(m[1].shape, 1), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_file_name = 'models/og_{}_{}.h5'.format(int(shared_percent * 100), num_models)\n",
    "model.save(og_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model - 0\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/20\n",
      "21/21 [==============================] - 8s 401ms/step - loss: 0.0964 - val_loss: 0.0729\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 11s 504ms/step - loss: 0.0676 - val_loss: 0.0581\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - 11s 508ms/step - loss: 0.0504 - val_loss: 0.0441\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - 10s 498ms/step - loss: 0.0412 - val_loss: 0.0393\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 11s 512ms/step - loss: 0.0376 - val_loss: 0.0366\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 12s 583ms/step - loss: 0.0351 - val_loss: 0.0338\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 12s 559ms/step - loss: 0.0321 - val_loss: 0.0305\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 11s 512ms/step - loss: 0.0313 - val_loss: 0.0303\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 11s 541ms/step - loss: 0.0282 - val_loss: 0.0271\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - 11s 547ms/step - loss: 0.0265 - val_loss: 0.0254\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 12s 559ms/step - loss: 0.0249 - val_loss: 0.0244\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 12s 564ms/step - loss: 0.0239 - val_loss: 0.0236\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 12s 549ms/step - loss: 0.0230 - val_loss: 0.0241\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 12s 560ms/step - loss: 0.0225 - val_loss: 0.0219\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 12s 556ms/step - loss: 0.0215 - val_loss: 0.0215\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 12s 568ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 12s 563ms/step - loss: 0.0204 - val_loss: 0.0203\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 11s 536ms/step - loss: 0.0201 - val_loss: 0.0217\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 11s 539ms/step - loss: 0.0198 - val_loss: 0.0195\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 11s 537ms/step - loss: 0.0193 - val_loss: 0.0198\n",
      "Training model - 1\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/20\n",
      "21/21 [==============================] - 12s 571ms/step - loss: 0.0964 - val_loss: 0.0729\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 12s 580ms/step - loss: 0.0671 - val_loss: 0.0572\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - 12s 571ms/step - loss: 0.0509 - val_loss: 0.0442\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - 12s 571ms/step - loss: 0.0415 - val_loss: 0.0395\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 12s 572ms/step - loss: 0.0380 - val_loss: 0.0373\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 12s 567ms/step - loss: 0.0357 - val_loss: 0.0348\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 12s 562ms/step - loss: 0.0337 - val_loss: 0.0321\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 12s 575ms/step - loss: 0.0309 - val_loss: 0.0322\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 12s 571ms/step - loss: 0.0290 - val_loss: 0.0278\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - 12s 572ms/step - loss: 0.0269 - val_loss: 0.0260\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 12s 568ms/step - loss: 0.0255 - val_loss: 0.0248\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 12s 574ms/step - loss: 0.0245 - val_loss: 0.0239\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 12s 573ms/step - loss: 0.0234 - val_loss: 0.0230\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 12s 576ms/step - loss: 0.0228 - val_loss: 0.0223\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 12s 563ms/step - loss: 0.0219 - val_loss: 0.0222\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 12s 576ms/step - loss: 0.0213 - val_loss: 0.0210\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 12s 585ms/step - loss: 0.0210 - val_loss: 0.0207\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 12s 566ms/step - loss: 0.0203 - val_loss: 0.0211\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 12s 584ms/step - loss: 0.0201 - val_loss: 0.0197\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 13s 596ms/step - loss: 0.0198 - val_loss: 0.0198\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "for i in range(num_models):\n",
    "    print(\"Training model - {}\".format(i))\n",
    "    \n",
    "    model_train_data = np.vstack((shared_train_data, private_train_data[i]))\n",
    "    model_train_labels = np.vstack(\n",
    "        (shared_train_labels, private_train_labels[i]))\n",
    "\n",
    "    model = keras.models.load_model(og_file_name)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "    model.fit(model_train_data, model_train_data, epochs=20, batch_size=2048, validation_data=(model_train_labels, model_train_labels), callbacks=[early_stopping])\n",
    "\n",
    "    model_name = \"models/clip_1_5_NO_{}_{}_{}.h5\".format(i, int(shared_percent * 100), num_models)\n",
    "    model.save(model_name)\n",
    "    \n",
    "    save_weights(model, \"clip_1_5_NO_{}_{}_{}\".format(i, int(shared_percent * 100), num_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
