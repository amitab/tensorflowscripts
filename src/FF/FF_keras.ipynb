{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing 'Age' values: 177\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd        # For loading and processing the dataset\n",
    "import tensorflow as tf    # Of course, we need TensorFlow.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the CSV input file and show first 5 rows\n",
    "df_train = pd.read_csv('input/train.csv')\n",
    "df_train.head(5)\n",
    "\n",
    "# To make 'Sex' numeric, we replace 'female' by 0 and 'male' by 1\n",
    "df_train['Sex'] = df_train['Sex'].map({'female':0, 'male':1}).astype(int) \n",
    "\n",
    "# We replace 'Embarked' by three dummy variables 'Embarked_S', 'Embarked_C', and 'Embarked Q',\n",
    "# which are 1 if the person embarked there, and 0 otherwise.\n",
    "df_train = pd.concat([df_train, pd.get_dummies(df_train['Embarked'], prefix='Embarked')], axis=1)\n",
    "df_train = df_train.drop('Embarked', axis=1)\n",
    "\n",
    "# We normalize the age and the fare by subtracting their mean and dividing by the standard deviation\n",
    "age_mean = df_train['Age'].mean()\n",
    "age_std = df_train['Age'].std()\n",
    "df_train['Age'] = (df_train['Age'] - age_mean) / age_std\n",
    "\n",
    "fare_mean = df_train['Fare'].mean()\n",
    "fare_std = df_train['Fare'].std()\n",
    "df_train['Fare'] = (df_train['Fare'] - fare_mean) / fare_std\n",
    "\n",
    "# In many cases, the 'Age' is missing - which can cause problems. Let's look how bad it is:\n",
    "print(\"Number of missing 'Age' values: {:d}\".format(df_train['Age'].isnull().sum()))\n",
    "\n",
    "# A simple method to handle these missing values is to replace them by the mean age.\n",
    "df_train['Age'] = df_train['Age'].fillna(df_train['Age'].mean())\n",
    "\n",
    "df_train = df_train.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# With that, we're almost ready for training\n",
    "df_train.head()\n",
    "\n",
    "# Finally, we convert the Pandas dataframe to a NumPy array, and split it into a training and test set\n",
    "X_train = df_train.drop('Survived', axis=1).to_numpy()\n",
    "y_train = df_train['Survived'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# We'll build a classifier with two classes: \"survived\" and \"didn't survive\",\n",
    "# so we create the according labels\n",
    "# This is taken from https://www.kaggle.com/klepacz/titanic/tensor-flow\n",
    "labels_train = (np.arange(2) == y_train[:,None]).astype(np.float32)\n",
    "labels_test = (np.arange(2) == y_test[:,None]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.530005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.502163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.254646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.488580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364911</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364911</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex       Age  SibSp  Parch      Fare  \\\n",
       "0            1         0       3    1 -0.530005      1      0 -0.502163   \n",
       "1            2         1       1    0  0.571430      1      0  0.786404   \n",
       "2            3         1       3    0 -0.254646      0      0 -0.488580   \n",
       "3            4         1       1    0  0.364911      1      0  0.420494   \n",
       "4            5         0       3    1  0.364911      0      0 -0.486064   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0           0           1  \n",
       "1           1           0           0  \n",
       "2           0           0           1  \n",
       "3           0           0           1  \n",
       "4           0           0           1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>517.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.960715e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.436762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>794.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.003921e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.030354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>577.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.960715e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.386454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>344.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.234859e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.386454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>269.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.948225e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.440127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>669.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.156290e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.486064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>387.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.975639e+00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.295729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>748.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.071266e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.386454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>607.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.071266e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.489167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>758.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.053640e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.416639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2             3    4    5         6    7    8    9\n",
       "0    517.0  2.0  0.0  2.960715e-01  0.0  0.0 -0.436762  0.0  0.0  1.0\n",
       "1    794.0  1.0  1.0  2.003921e-16  0.0  0.0 -0.030354  1.0  0.0  0.0\n",
       "2    577.0  2.0  0.0  2.960715e-01  0.0  0.0 -0.386454  0.0  0.0  1.0\n",
       "3    344.0  2.0  1.0 -3.234859e-01  0.0  0.0 -0.386454  0.0  0.0  1.0\n",
       "4    269.0  1.0  0.0  1.948225e+00  0.0  1.0  2.440127  0.0  0.0  1.0\n",
       "..     ...  ...  ...           ...  ...  ...       ...  ...  ...  ...\n",
       "707  669.0  3.0  1.0  9.156290e-01  0.0  0.0 -0.486064  0.0  0.0  1.0\n",
       "708  387.0  3.0  1.0 -1.975639e+00  5.0  2.0  0.295729  0.0  0.0  1.0\n",
       "709  748.0  2.0  0.0  2.071266e-02  0.0  0.0 -0.386454  0.0  0.0  1.0\n",
       "710  607.0  3.0  1.0  2.071266e-02  0.0  0.0 -0.489167  0.0  0.0  1.0\n",
       "711  758.0  2.0  1.0 -8.053640e-01  0.0  0.0 -0.416639  0.0  0.0  1.0\n",
       "\n",
       "[712 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # tf.keras.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "  loss=tf.keras.losses.BinaryCrossentropy(\n",
    "    from_logits=True, label_smoothing=0, reduction=\"auto\", name=\"binary_crossentropy\"),\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.layers[4].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 0.6804 - accuracy: 0.6562WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0071s). Check your callbacks.\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7059 - accuracy: 0.5955\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7000 - accuracy: 0.6067\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.6152\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.6096\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.6081\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.6138\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.6110\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.6124\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.6110\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.6110\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.6166\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.6081\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.6096\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7163 - accuracy: 0.5688\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7117 - accuracy: 0.5787\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7113 - accuracy: 0.5801\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7144 - accuracy: 0.5744\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7008 - accuracy: 0.5983\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.6166\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.6081\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.6096\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.6208\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.6110\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.6025\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.6025\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.6124\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.6096\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.6110\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.6110\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.6096\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.6124\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.6124\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.6124\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.6124\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.6124\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.6124\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.6124\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6968 - accuracy: 0.6124\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.6124\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.6110\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.6096\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.6124\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.6124\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.6124\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.6124\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.6110\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.6124\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.6124\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.6110\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.6124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fafc063b040>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbCallBack = tf.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "model.fit(\n",
    "  X_train,\n",
    "  labels_train, # training targets\n",
    "  epochs=50,\n",
    "  callbacks=[tbCallBack]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "6/6 [==============================] - 0s 814us/step - loss: 0.6876 - accuracy: 0.6313\n",
      "test loss, test acc: [0.6876347661018372, 0.6312848925590515]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, labels_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on train data\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6969 - accuracy: 0.6124\n",
      "train loss, train acc: [0.6968668699264526, 0.6123595237731934]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on train data\")\n",
    "results = model.evaluate(X_train, labels_train)\n",
    "print(\"train loss, train acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test_seen.out', X_test, header=\"{},{}\".format(*X_test.shape), delimiter=\",\")\n",
    "np.savetxt('labels_test_seen.out', labels_test, header=\"{},{}\".format(*labels_test.shape), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_eval = np.transpose(model.layers[0].get_weights()[0])\n",
    "w2_eval = np.transpose(model.layers[2].get_weights()[0])\n",
    "wo_eval = np.transpose(model.layers[4].get_weights()[0])\n",
    "\n",
    "b1_eval = model.layers[0].get_weights()[1]\n",
    "b2_eval = model.layers[2].get_weights()[1]\n",
    "bo_eval = model.layers[4].get_weights()[1]\n",
    "\n",
    "np.savetxt('w1.out', w1_eval, header=\"{},{}\".format(*w1_eval.shape), delimiter=\",\")\n",
    "np.savetxt('w2.out', w2_eval, header=\"{},{}\".format(*w2_eval.shape), delimiter=\",\")\n",
    "np.savetxt('wo.out', wo_eval, header=\"{},{}\".format(*wo_eval.shape), delimiter=\",\")\n",
    "np.savetxt('b1.out', b1_eval, header=\"{},{}\".format(b1_eval.shape[0], 1), delimiter=\",\")\n",
    "np.savetxt('b2.out', b2_eval, header=\"{},{}\".format(b2_eval.shape[0], 1), delimiter=\",\")\n",
    "np.savetxt('bo.out', bo_eval, header=\"{},{}\".format(bo_eval.shape[0], 1), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxmltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 15 -> 9\n",
      "The maximum opset needed by this model is only 9.\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnxmltools.convert_keras(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxmltools.utils.save_model(onnx_model, 'model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
