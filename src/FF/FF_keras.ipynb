{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing 'Age' values: 177\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd        # For loading and processing the dataset\n",
    "import tensorflow as tf    # Of course, we need TensorFlow.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the CSV input file and show first 5 rows\n",
    "df_train = pd.read_csv('input/train.csv')\n",
    "df_train.head(5)\n",
    "\n",
    "# To make 'Sex' numeric, we replace 'female' by 0 and 'male' by 1\n",
    "df_train['Sex'] = df_train['Sex'].map({'female':0, 'male':1}).astype(int) \n",
    "\n",
    "# We replace 'Embarked' by three dummy variables 'Embarked_S', 'Embarked_C', and 'Embarked Q',\n",
    "# which are 1 if the person embarked there, and 0 otherwise.\n",
    "df_train = pd.concat([df_train, pd.get_dummies(df_train['Embarked'], prefix='Embarked')], axis=1)\n",
    "df_train = df_train.drop('Embarked', axis=1)\n",
    "\n",
    "# We normalize the age and the fare by subtracting their mean and dividing by the standard deviation\n",
    "age_mean = df_train['Age'].mean()\n",
    "age_std = df_train['Age'].std()\n",
    "df_train['Age'] = (df_train['Age'] - age_mean) / age_std\n",
    "\n",
    "fare_mean = df_train['Fare'].mean()\n",
    "fare_std = df_train['Fare'].std()\n",
    "df_train['Fare'] = (df_train['Fare'] - fare_mean) / fare_std\n",
    "\n",
    "# In many cases, the 'Age' is missing - which can cause problems. Let's look how bad it is:\n",
    "print(\"Number of missing 'Age' values: {:d}\".format(df_train['Age'].isnull().sum()))\n",
    "\n",
    "# A simple method to handle these missing values is to replace them by the mean age.\n",
    "df_train['Age'] = df_train['Age'].fillna(df_train['Age'].mean())\n",
    "\n",
    "df_train = df_train.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# With that, we're almost ready for training\n",
    "df_train.head()\n",
    "\n",
    "# Finally, we convert the Pandas dataframe to a NumPy array, and split it into a training and test set\n",
    "X_train = df_train.drop('Survived', axis=1).to_numpy()\n",
    "y_train = df_train['Survived'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# We'll build a classifier with two classes: \"survived\" and \"didn't survive\",\n",
    "# so we create the according labels\n",
    "# This is taken from https://www.kaggle.com/klepacz/titanic/tensor-flow\n",
    "labels_train = (np.arange(2) == y_train[:,None]).astype(np.float32)\n",
    "labels_test = (np.arange(2) == y_test[:,None]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.530005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.502163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.254646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.488580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364911</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364911</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex       Age  SibSp  Parch      Fare  Embarked_C  \\\n",
       "0         0       3    1 -0.530005      1      0 -0.502163           0   \n",
       "1         1       1    0  0.571430      1      0  0.786404           1   \n",
       "2         1       3    0 -0.254646      0      0 -0.488580           0   \n",
       "3         1       1    0  0.364911      1      0  0.420494           0   \n",
       "4         0       3    1  0.364911      0      0 -0.486064           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0           0           1  \n",
       "1           0           0  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           0           1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.003921e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.814891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.676845e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.456886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.053640e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.386454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.234859e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.506188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.631441e+00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.018699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.955238e-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.285837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.003921e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.502666</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.837960e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.124850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.300051e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.489167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.003921e-16</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.751524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1             2    3    4         5    6    7    8\n",
       "0    1.0  1.0  2.003921e-16  0.0  0.0  3.814891  0.0  0.0  1.0\n",
       "1    3.0  1.0 -6.676845e-01  0.0  0.0 -0.456886  0.0  0.0  1.0\n",
       "2    2.0  1.0 -8.053640e-01  0.0  0.0 -0.386454  0.0  0.0  1.0\n",
       "3    3.0  1.0 -3.234859e-01  0.0  0.0 -0.506188  0.0  0.0  1.0\n",
       "4    3.0  0.0 -1.631441e+00  4.0  2.0 -0.018699  0.0  0.0  1.0\n",
       "..   ...  ...           ...  ...  ...       ...  ...  ...  ...\n",
       "707  3.0  0.0  8.955238e-02  1.0  0.0 -0.285837  0.0  0.0  1.0\n",
       "708  3.0  1.0  2.003921e-16  0.0  0.0 -0.502666  1.0  0.0  0.0\n",
       "709  2.0  1.0 -1.837960e+00  1.0  1.0 -0.124850  0.0  0.0  1.0\n",
       "710  3.0  1.0 -5.300051e-01  0.0  0.0 -0.489167  0.0  0.0  1.0\n",
       "711  3.0  1.0  2.003921e-16  8.0  2.0  0.751524  0.0  0.0  1.0\n",
       "\n",
       "[712 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # tf.keras.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "  loss=tf.keras.losses.BinaryCrossentropy(\n",
    "    from_logits=True, label_smoothing=0, reduction=\"auto\", name=\"binary_crossentropy\"),\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.layers[4].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 0.7361 - accuracy: 0.4375WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0063s). Check your callbacks.\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7253 - accuracy: 0.4958\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7206 - accuracy: 0.5365\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.5576\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7082 - accuracy: 0.5941\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.6236\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7006 - accuracy: 0.6011\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.6320\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.6124\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.6278\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.6264\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.6292\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.6292\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.6306\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.6278\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.6236\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.6320\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.6152\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.6236\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.6208\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.6292\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.6166\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.6222\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.6278\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.6320\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.6278\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.6320\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6779 - accuracy: 0.6250\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.6348\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.6320\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6773 - accuracy: 0.6433\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6776 - accuracy: 0.6334\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6744 - accuracy: 0.6390\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.6447\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6757 - accuracy: 0.6348\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.6362\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6748 - accuracy: 0.6404\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.6419\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.6772 - accuracy: 0.6404\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.6461\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.6362\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.6489\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.6559\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.6461\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6691 - accuracy: 0.6531\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.6559\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.6503\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6710 - accuracy: 0.6629\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.6559\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6712 - accuracy: 0.6559\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.6475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faf5807c0a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbCallBack = tf.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "model.fit(\n",
    "  X_train,\n",
    "  labels_train, # training targets\n",
    "  epochs=50,\n",
    "  callbacks=[tbCallBack]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7183902  0.2816098 ]\n",
      " [0.9592674  0.04073264]\n",
      " [0.46977243 0.53022754]\n",
      " [0.89555806 0.10444196]\n",
      " [0.960958   0.03904193]\n",
      " [0.90012753 0.09987248]\n",
      " [0.937597   0.062403  ]\n",
      " [0.93007326 0.06992667]\n",
      " [0.9164197  0.08358035]\n",
      " [0.9618704  0.03812966]\n",
      " [0.8336214  0.16637856]\n",
      " [0.89555806 0.10444196]\n",
      " [0.5638575  0.43614256]\n",
      " [0.87702405 0.12297591]\n",
      " [0.5409988  0.45900118]\n",
      " [0.6385901  0.36140987]\n",
      " [0.88937944 0.11062058]\n",
      " [0.38916415 0.6108358 ]\n",
      " [0.95563793 0.04436211]\n",
      " [0.399889   0.600111  ]\n",
      " [0.9560812  0.04391873]\n",
      " [0.7461668  0.2538332 ]\n",
      " [0.71586686 0.2841331 ]\n",
      " [0.79814357 0.20185639]\n",
      " [0.9473134  0.05268655]\n",
      " [0.8972593  0.10274069]\n",
      " [0.80456734 0.19543266]\n",
      " [0.8456774  0.15432261]\n",
      " [0.7520534  0.24794663]\n",
      " [0.9311953  0.06880472]\n",
      " [0.8815973  0.11840266]\n",
      " [0.83954537 0.16045459]\n",
      " [0.8961069  0.10389315]\n",
      " [0.8624292  0.13757078]\n",
      " [0.937597   0.062403  ]\n",
      " [0.961722   0.03827791]\n",
      " [0.47952425 0.5204758 ]\n",
      " [0.46762574 0.5323742 ]\n",
      " [0.5556253  0.44437465]\n",
      " [0.8098821  0.19011794]\n",
      " [0.9474404  0.05255963]\n",
      " [0.30055207 0.69944793]\n",
      " [0.8704437  0.12955625]\n",
      " [0.26179507 0.73820496]\n",
      " [0.9522061  0.04779388]\n",
      " [0.5290195  0.47098053]\n",
      " [0.8954809  0.10451913]\n",
      " [0.5205133  0.47948667]\n",
      " [0.9560812  0.04391873]\n",
      " [0.9430366  0.0569633 ]\n",
      " [0.80487394 0.19512601]\n",
      " [0.5140639  0.48593614]\n",
      " [0.91832364 0.08167639]\n",
      " [0.9006636  0.09933641]\n",
      " [0.9569426  0.04305737]\n",
      " [0.937597   0.062403  ]\n",
      " [0.9624611  0.0375389 ]\n",
      " [0.6784025  0.32159758]\n",
      " [0.85221475 0.14778523]\n",
      " [0.9548521  0.04514782]\n",
      " [0.8302644  0.16973564]\n",
      " [0.39980695 0.6001931 ]\n",
      " [0.9154142  0.08458581]\n",
      " [0.94289726 0.05710274]\n",
      " [0.7698224  0.23017758]\n",
      " [0.9535712  0.04642879]\n",
      " [0.93007326 0.06992667]\n",
      " [0.9613408  0.03865921]\n",
      " [0.22262558 0.77737445]\n",
      " [0.49887666 0.50112337]\n",
      " [0.3115987  0.68840134]\n",
      " [0.85748607 0.14251396]\n",
      " [0.91846657 0.08153339]\n",
      " [0.9074028  0.09259715]\n",
      " [0.94473815 0.05526184]\n",
      " [0.8992057  0.10079436]\n",
      " [0.91890514 0.08109479]\n",
      " [0.7478735  0.25212657]\n",
      " [0.9546295  0.04537047]\n",
      " [0.9506833  0.0493167 ]\n",
      " [0.9507428  0.0492572 ]\n",
      " [0.9492791  0.05072089]\n",
      " [0.6397822  0.36021775]\n",
      " [0.793974   0.20602608]\n",
      " [0.8059472  0.19405283]\n",
      " [0.8036548  0.19634528]\n",
      " [0.7830367  0.21696329]\n",
      " [0.95638555 0.04361444]\n",
      " [0.9560812  0.04391873]\n",
      " [0.89037484 0.10962519]\n",
      " [0.957322   0.04267799]\n",
      " [0.87877095 0.12122905]\n",
      " [0.85009754 0.1499025 ]\n",
      " [0.8855778  0.11442219]\n",
      " [0.9575167  0.04248336]\n",
      " [0.5318947  0.46810538]\n",
      " [0.86281174 0.1371882 ]\n",
      " [0.8992752  0.1007248 ]\n",
      " [0.8786322  0.12136786]\n",
      " [0.9213148  0.07868522]\n",
      " [0.9491781  0.05082192]\n",
      " [0.93760496 0.06239503]\n",
      " [0.86862826 0.1313717 ]\n",
      " [0.9560083  0.04399171]\n",
      " [0.4399001  0.5600999 ]\n",
      " [0.8632864  0.13671362]\n",
      " [0.9516292  0.04837075]\n",
      " [0.51367605 0.48632392]\n",
      " [0.7241656  0.27583435]\n",
      " [0.91424644 0.08575353]\n",
      " [0.9560812  0.04391873]\n",
      " [0.88808507 0.11191497]\n",
      " [0.81466836 0.18533169]\n",
      " [0.49477622 0.50522375]\n",
      " [0.84587616 0.15412389]\n",
      " [0.9214279  0.07857206]\n",
      " [0.9556863  0.04431367]\n",
      " [0.26973802 0.7302619 ]\n",
      " [0.72354454 0.27645552]\n",
      " [0.68637127 0.3136287 ]\n",
      " [0.95432705 0.04567295]\n",
      " [0.89999723 0.10000274]\n",
      " [0.73950636 0.2604937 ]\n",
      " [0.89690924 0.10309076]\n",
      " [0.8958106  0.1041894 ]\n",
      " [0.9037227  0.09627732]\n",
      " [0.94663256 0.05336748]\n",
      " [0.949371   0.05062899]\n",
      " [0.9138893  0.0861107 ]\n",
      " [0.94281733 0.05718269]\n",
      " [0.9609427  0.03905728]\n",
      " [0.9541962  0.04580381]\n",
      " [0.9214279  0.07857206]\n",
      " [0.92070425 0.07929576]\n",
      " [0.8907177  0.10928228]\n",
      " [0.79681367 0.20318632]\n",
      " [0.95503986 0.04496016]\n",
      " [0.82528293 0.17471707]\n",
      " [0.76255745 0.23744252]\n",
      " [0.95638555 0.04361444]\n",
      " [0.95292366 0.04707636]\n",
      " [0.89555806 0.10444196]\n",
      " [0.84422433 0.15577571]\n",
      " [0.94725424 0.0527457 ]\n",
      " [0.95952827 0.04047166]\n",
      " [0.9574844  0.04251559]\n",
      " [0.5167148  0.48328522]\n",
      " [0.95362794 0.04637213]\n",
      " [0.8083073  0.19169274]\n",
      " [0.9070189  0.09298114]\n",
      " [0.9158697  0.08413033]\n",
      " [0.96226954 0.03773047]\n",
      " [0.8148368  0.18516324]\n",
      " [0.5199999  0.48000002]\n",
      " [0.8419878  0.15801223]\n",
      " [0.94007903 0.05992103]\n",
      " [0.45744374 0.5425562 ]\n",
      " [0.73743564 0.26256433]\n",
      " [0.3409434  0.6590566 ]\n",
      " [0.9201768  0.07982317]\n",
      " [0.94377166 0.05622836]\n",
      " [0.87877595 0.12122402]\n",
      " [0.72892284 0.27107716]\n",
      " [0.9471195  0.05288047]\n",
      " [0.87769586 0.12230412]\n",
      " [0.95773023 0.04226974]\n",
      " [0.87931687 0.12068316]\n",
      " [0.8954321  0.10456788]\n",
      " [0.9085154  0.09148455]\n",
      " [0.92349046 0.07650954]\n",
      " [0.67909324 0.3209067 ]\n",
      " [0.8951792  0.10482074]\n",
      " [0.9512069  0.04879308]\n",
      " [0.9326312  0.06736887]\n",
      " [0.9557034  0.04429659]\n",
      " [0.95200413 0.04799589]\n",
      " [0.8610609  0.13893902]\n",
      " [0.92862433 0.07137571]\n",
      " [0.4624419  0.5375581 ]]\n"
     ]
    }
   ],
   "source": [
    "op = model.predict(X_test)\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "6/6 [==============================] - 0s 653us/step - loss: 0.6642 - accuracy: 0.6816\n",
      "test loss, test acc: [0.6642029881477356, 0.6815642714500427]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, labels_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on train data\n",
      "23/23 [==============================] - 0s 981us/step - loss: 0.6639 - accuracy: 0.6643\n",
      "train loss, train acc: [0.6639474630355835, 0.6643258333206177]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on train data\")\n",
    "results = model.evaluate(X_train, labels_train)\n",
    "print(\"train loss, train acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test_seen.out', X_test, header=\"{},{}\".format(*X_test.shape), delimiter=\",\")\n",
    "np.savetxt('labels_test_seen.out', labels_test, header=\"{},{}\".format(*labels_test.shape), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_eval = np.transpose(model.layers[0].get_weights()[0])\n",
    "w2_eval = np.transpose(model.layers[2].get_weights()[0])\n",
    "wo_eval = np.transpose(model.layers[4].get_weights()[0])\n",
    "\n",
    "b1_eval = model.layers[0].get_weights()[1]\n",
    "b2_eval = model.layers[2].get_weights()[1]\n",
    "bo_eval = model.layers[4].get_weights()[1]\n",
    "\n",
    "np.savetxt('w1.out', w1_eval, header=\"{},{}\".format(*w1_eval.shape), delimiter=\",\")\n",
    "np.savetxt('w2.out', w2_eval, header=\"{},{}\".format(*w2_eval.shape), delimiter=\",\")\n",
    "np.savetxt('wo.out', wo_eval, header=\"{},{}\".format(*wo_eval.shape), delimiter=\",\")\n",
    "np.savetxt('b1.out', b1_eval, header=\"{},{}\".format(b1_eval.shape[0], 1), delimiter=\",\")\n",
    "np.savetxt('b2.out', b2_eval, header=\"{},{}\".format(b2_eval.shape[0], 1), delimiter=\",\")\n",
    "np.savetxt('bo.out', bo_eval, header=\"{},{}\".format(bo_eval.shape[0], 1), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxmltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 15 -> 9\n",
      "The maximum opset needed by this model is only 9.\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnxmltools.convert_keras(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxmltools.utils.save_model(onnx_model, 'model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
