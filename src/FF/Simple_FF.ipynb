{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd        # For loading and processing the dataset\n",
    "import tensorflow as tf    # Of course, we need TensorFlow.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('FF/input/train.csv')\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['PassengerId','Name','Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Sex'] = df_train['Sex'].map({'female':0, 'male':1}).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We replace 'Embarked' by three dummy variables 'Embarked_S', 'Embarked_C', and 'Embarked Q',\n",
    "# which are 1 if the person embarked there, and 0 otherwise.\n",
    "df_train = pd.concat([df_train, pd.get_dummies(df_train['Embarked'], prefix='Embarked')], axis=1)\n",
    "df_train = df_train.drop('Embarked', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We normalize the age and the fare by subtracting their mean and dividing by the standard deviation\n",
    "age_mean = df_train['Age'].mean()\n",
    "age_std = df_train['Age'].std()\n",
    "df_train['Age'] = (df_train['Age'] - age_mean) / age_std\n",
    "\n",
    "fare_mean = df_train['Fare'].mean()\n",
    "fare_std = df_train['Fare'].std()\n",
    "df_train['Fare'] = (df_train['Fare'] - fare_mean) / fare_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing 'Age' values: 177\n"
     ]
    }
   ],
   "source": [
    "# In many cases, the 'Age' is missing - which can cause problems. Let's look how bad it is:\n",
    "print(\"Number of missing 'Age' values: {:d}\".format(df_train['Age'].isnull().sum()))\n",
    "\n",
    "# A simple method to handle these missing values is to replace them by the mean age.\n",
    "df_train['Age'] = df_train['Age'].fillna(df_train['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.530005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.502163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.254646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.488580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364911</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364911</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex       Age  SibSp  Parch      Fare  Embarked_C  \\\n",
       "0         0       3    1 -0.530005      1      0 -0.502163           0   \n",
       "1         1       1    0  0.571430      1      0  0.786404           1   \n",
       "2         1       3    0 -0.254646      0      0 -0.488580           0   \n",
       "3         1       1    0  0.364911      1      0  0.420494           0   \n",
       "4         0       3    1  0.364911      0      0 -0.486064           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0           0           1  \n",
       "1           0           0  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           0           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we convert the Pandas dataframe to a NumPy array, and split it into a training and test set\n",
    "X_train = df_train.drop('Survived', axis=1).to_numpy()\n",
    "y_train = df_train['Survived'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "np.savetxt('test_seen.out', X_test, header=\"{},{}\".format(*X_test.shape), delimiter=\",\")\n",
    "np.savetxt('train.out', X_train, header=\"{},{}\".format(*X_train.shape), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll build a classifier with two classes: \"survived\" and \"didn't survive\",\n",
    "# so we create the according labels\n",
    "# This is taken from https://www.kaggle.com/klepacz/titanic/tensor-flow\n",
    "labels_train = (np.arange(2) == y_train[:,None]).astype(np.float32)\n",
    "labels_test = (np.arange(2) == y_test[:,None]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "inputs = tf.compat.v1.placeholder(tf.float32, shape=(None, X_train.shape[1]), name='inputs')\n",
    "label = tf.compat.v1.placeholder(tf.float32, shape=(None, 2), name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layer\n",
    "hid1_size = 128\n",
    "w1 = tf.Variable(tf.random.normal([hid1_size, X_train.shape[1]], stddev=0.01), name='w1')\n",
    "b1 = tf.Variable(tf.constant(0.1, shape=(hid1_size, 1)), name='b1')\n",
    "y1 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(w1, tf.transpose(a=inputs)), b1)), rate=1 - (0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second layer\n",
    "hid2_size = 256\n",
    "w2 = tf.Variable(tf.random.normal([hid2_size, hid1_size], stddev=0.01), name='w2')\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=(hid2_size, 1)), name='b2')\n",
    "y2 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(w2, y1), b2)), rate=1 - (0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "wo = tf.Variable(tf.random.normal([2, hid2_size], stddev=0.01), name='wo')\n",
    "bo = tf.Variable(tf.random.normal([2, 1]), name='bo')\n",
    "yo = tf.transpose(a=tf.add(tf.matmul(wo, y2), bo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "lr = tf.compat.v1.placeholder(tf.float32, shape=(), name='learning_rate')\n",
    "loss = tf.reduce_mean(input_tensor=tf.nn.softmax_cross_entropy_with_logits(logits=yo, labels=tf.stop_gradient(label)))\n",
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "pred = tf.nn.softmax(yo)\n",
    "pred_label = tf.argmax(input=pred, axis=1)\n",
    "correct_prediction = tf.equal(tf.argmax(input=pred, axis=1), tf.argmax(input=label, axis=1))\n",
    "accuracy = tf.reduce_mean(input_tensor=tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create operation which will initialize all variables\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "# Configure GPU not to use all memory\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Start a new tensorflow session and initialize variables\n",
    "sess = tf.compat.v1.InteractiveSession(config=config)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0    Train Cost: 0.6462\n",
      "Epoch:  10    Train Cost: 0.5074\n",
      "Epoch:  20    Train Cost: 0.4615\n",
      "Epoch:  30    Train Cost: 0.4864\n",
      "Epoch:  40    Train Cost: 0.4762\n",
      "Epoch:   0    Train Cost: 0.4366\n",
      "Epoch:  10    Train Cost: 0.3931\n",
      "Epoch:  20    Train Cost: 0.3789\n",
      "Epoch:  30    Train Cost: 0.3813\n",
      "Epoch:  40    Train Cost: 0.3887\n"
     ]
    }
   ],
   "source": [
    "writer = tf.compat.v1.summary.FileWriter('logs', sess.graph)\n",
    "\n",
    "# This is the main training loop: we train for 50 epochs with a learning rate of 0.05 and another \n",
    "# 50 epochs with a smaller learning rate of 0.01\n",
    "for learning_rate in [0.05, 0.01]:\n",
    "    for epoch in range(50):\n",
    "        avg_cost = 0.0\n",
    "\n",
    "        # For each epoch, we go through all the samples we have.\n",
    "        for i in range(X_train.shape[0]):\n",
    "            # Finally, this is where the magic happens: run our optimizer, feed the current example into X and the current target into Y\n",
    "            _, c = sess.run([optimizer, loss], feed_dict={lr:learning_rate, \n",
    "                                                          inputs: X_train[i, None],\n",
    "                                                          label: labels_train[i, None]})\n",
    "            avg_cost += c\n",
    "        avg_cost /= X_train.shape[0]    \n",
    "\n",
    "        # Print the cost in this epcho to the console.\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch: {:3d}    Train Cost: {:.4f}\".format(epoch, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 84.41%\n",
      "Test accuracy:  79.89%\n"
     ]
    }
   ],
   "source": [
    "acc_train = accuracy.eval(feed_dict={inputs: X_train, label: labels_train})\n",
    "print(\"Train accuracy: {:3.2f}%\".format(acc_train*100.0))\n",
    "acc_test = accuracy.eval(feed_dict={inputs: X_test, label: labels_test})\n",
    "print(\"Test accuracy:  {:3.2f}%\".format(acc_test*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'w1:0' shape=(128, 9) dtype=float32>,\n",
       " <tf.Variable 'b1:0' shape=(128, 1) dtype=float32>,\n",
       " <tf.Variable 'w2:0' shape=(256, 128) dtype=float32>,\n",
       " <tf.Variable 'b2:0' shape=(256, 1) dtype=float32>,\n",
       " <tf.Variable 'wo:0' shape=(2, 256) dtype=float32>,\n",
       " <tf.Variable 'bo:0' shape=(2, 1) dtype=float32>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars = tf.compat.v1.trainable_variables()\n",
    "vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_vals = sess.run(vars)\n",
    "np.savetxt('w1.out', vars_vals[0], header=\"{},{}\".format(*vars_vals[0].shape), delimiter=\",\")\n",
    "np.savetxt('b1.out', vars_vals[1], header=\"{},{}\".format(*vars_vals[1].shape), delimiter=\",\")\n",
    "np.savetxt('w2.out', vars_vals[2], header=\"{},{}\".format(*vars_vals[2].shape), delimiter=\",\")\n",
    "np.savetxt('b2.out', vars_vals[3], header=\"{},{}\".format(*vars_vals[3].shape), delimiter=\",\")\n",
    "np.savetxt('wo.out', vars_vals[4], header=\"{},{}\".format(*vars_vals[4].shape), delimiter=\",\")\n",
    "np.savetxt('bo.out', vars_vals[5], header=\"{},{}\".format(*vars_vals[5].shape), delimiter=\",\")\n",
    "np.savetxt('labels_test_seen.out', labels_test, header=\"{},{}\".format(*labels_test.shape), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = pred.eval(feed_dict={inputs: X_test})\n",
    "#op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.51872003e-01 2.48128012e-01]\n",
      " [9.07114565e-01 9.28854197e-02]\n",
      " [2.35386550e-01 7.64613450e-01]\n",
      " [1.28746629e-01 8.71253371e-01]\n",
      " [8.29958200e-01 1.70041814e-01]\n",
      " [8.64146054e-01 1.35853931e-01]\n",
      " [5.97017825e-01 4.02982175e-01]\n",
      " [8.61660004e-01 1.38340056e-01]\n",
      " [8.64882231e-01 1.35117710e-01]\n",
      " [8.52846086e-01 1.47153869e-01]\n",
      " [5.78812897e-01 4.21187133e-01]\n",
      " [8.64469409e-01 1.35530546e-01]\n",
      " [8.00948918e-01 1.99051067e-01]\n",
      " [8.66123438e-01 1.33876562e-01]\n",
      " [8.89432311e-01 1.10567719e-01]\n",
      " [8.07019532e-01 1.92980498e-01]\n",
      " [7.34794199e-01 2.65205830e-01]\n",
      " [4.44113493e-01 5.55886507e-01]\n",
      " [8.31493258e-01 1.68506771e-01]\n",
      " [5.26672482e-01 4.73327518e-01]\n",
      " [9.38840985e-01 6.11589924e-02]\n",
      " [9.00863763e-03 9.90991354e-01]\n",
      " [3.85664701e-01 6.14335239e-01]\n",
      " [3.06600612e-09 1.00000000e+00]\n",
      " [6.11742735e-01 3.88257265e-01]\n",
      " [8.46845448e-01 1.53154567e-01]\n",
      " [6.81699097e-01 3.18300873e-01]\n",
      " [3.53987455e-01 6.46012545e-01]\n",
      " [3.61731529e-01 6.38268471e-01]\n",
      " [8.33734155e-01 1.66265786e-01]\n",
      " [2.92479634e-01 7.07520366e-01]\n",
      " [8.90446663e-01 1.09553292e-01]\n",
      " [8.43933523e-01 1.56066507e-01]\n",
      " [6.60503954e-02 9.33949590e-01]\n",
      " [5.47414780e-01 4.52585250e-01]\n",
      " [4.37625204e-06 9.99995589e-01]\n",
      " [2.60098875e-01 7.39901185e-01]\n",
      " [2.96973740e-03 9.97030258e-01]\n",
      " [8.67102504e-01 1.32897556e-01]\n",
      " [7.04354107e-01 2.95645893e-01]\n",
      " [2.44139910e-01 7.55860090e-01]\n",
      " [2.64761239e-01 7.35238731e-01]\n",
      " [6.57761991e-01 3.42238039e-01]\n",
      " [1.13434479e-01 8.86565566e-01]\n",
      " [9.03224945e-01 9.67749953e-02]\n",
      " [3.99174929e-01 6.00825071e-01]\n",
      " [4.71843362e-01 5.28156698e-01]\n",
      " [3.18851210e-02 9.68114913e-01]\n",
      " [8.50411594e-01 1.49588391e-01]\n",
      " [8.64202261e-01 1.35797739e-01]\n",
      " [8.01127791e-01 1.98872283e-01]\n",
      " [9.11956310e-01 8.80436823e-02]\n",
      " [2.05549821e-02 9.79445040e-01]\n",
      " [8.60673547e-01 1.39326468e-01]\n",
      " [3.04498047e-01 6.95501983e-01]\n",
      " [9.12799895e-01 8.72000828e-02]\n",
      " [5.89175289e-03 9.94108200e-01]\n",
      " [8.82901132e-01 1.17098883e-01]\n",
      " [9.06831443e-01 9.31685790e-02]\n",
      " [5.46986997e-01 4.53013062e-01]\n",
      " [8.83454740e-01 1.16545253e-01]\n",
      " [4.40443069e-01 5.59556961e-01]\n",
      " [8.35079730e-01 1.64920285e-01]\n",
      " [1.83743760e-01 8.16256225e-01]\n",
      " [6.98673399e-03 9.93013322e-01]\n",
      " [9.10329401e-01 8.96705911e-02]\n",
      " [8.15793633e-01 1.84206307e-01]\n",
      " [1.34691656e-01 8.65308344e-01]\n",
      " [6.51301801e-01 3.48698199e-01]\n",
      " [8.44539225e-01 1.55460760e-01]\n",
      " [5.06822407e-01 4.93177593e-01]\n",
      " [1.07318619e-05 9.99989271e-01]\n",
      " [8.50369215e-01 1.49630874e-01]\n",
      " [8.42466533e-01 1.57533482e-01]\n",
      " [2.14382380e-01 7.85617590e-01]\n",
      " [8.21665049e-01 1.78334907e-01]\n",
      " [8.44693482e-01 1.55306473e-01]\n",
      " [9.04130697e-01 9.58693027e-02]\n",
      " [5.17647088e-01 4.82352853e-01]\n",
      " [8.27728868e-01 1.72271162e-01]\n",
      " [8.82077277e-01 1.17922746e-01]\n",
      " [2.37360624e-07 9.99999762e-01]\n",
      " [8.40658784e-01 1.59341186e-01]\n",
      " [7.14177787e-01 2.85822183e-01]\n",
      " [9.07390594e-01 9.26094577e-02]\n",
      " [7.22804725e-01 2.77195245e-01]\n",
      " [9.17000789e-03 9.90829945e-01]\n",
      " [6.07085109e-01 3.92914891e-01]\n",
      " [5.29222310e-01 4.70777661e-01]\n",
      " [1.76675050e-04 9.99823391e-01]\n",
      " [1.70729365e-07 9.99999881e-01]\n",
      " [4.40955209e-03 9.95590448e-01]\n",
      " [7.72327006e-01 2.27673039e-01]\n",
      " [2.45346548e-03 9.97546494e-01]\n",
      " [7.58690596e-01 2.41309479e-01]\n",
      " [8.85566294e-01 1.14433780e-01]\n",
      " [8.58120799e-01 1.41879246e-01]\n",
      " [8.69529724e-01 1.30470306e-01]\n",
      " [3.30278069e-01 6.69721901e-01]\n",
      " [1.29467264e-01 8.70532811e-01]\n",
      " [8.87296736e-01 1.12703219e-01]\n",
      " [5.16207993e-01 4.83792037e-01]\n",
      " [8.22815418e-01 1.77184582e-01]\n",
      " [8.25592160e-01 1.74407884e-01]\n",
      " [6.03037119e-01 3.96962911e-01]\n",
      " [1.26148388e-03 9.98738587e-01]\n",
      " [2.55383730e-01 7.44616270e-01]\n",
      " [4.01214493e-07 9.99999642e-01]\n",
      " [8.66721988e-01 1.33278012e-01]\n",
      " [8.78642142e-01 1.21357881e-01]\n",
      " [9.33304727e-01 6.66953474e-02]\n",
      " [5.48414588e-01 4.51585382e-01]\n",
      " [1.02569908e-01 8.97430062e-01]\n",
      " [4.37981589e-03 9.95620191e-01]\n",
      " [8.69822919e-01 1.30177096e-01]\n",
      " [7.81496167e-01 2.18503788e-01]\n",
      " [8.29391658e-01 1.70608371e-01]\n",
      " [8.24402273e-01 1.75597712e-01]\n",
      " [4.53326553e-01 5.46673357e-01]\n",
      " [3.61504179e-04 9.99638438e-01]\n",
      " [4.17957108e-06 9.99995828e-01]\n",
      " [3.24948907e-01 6.75051153e-01]\n",
      " [8.74098957e-01 1.25901043e-01]\n",
      " [8.67158771e-01 1.32841259e-01]\n",
      " [9.05218065e-01 9.47818682e-02]\n",
      " [5.22549629e-01 4.77450401e-01]\n",
      " [6.46512330e-01 3.53487670e-01]\n",
      " [8.23662281e-02 9.17633772e-01]\n",
      " [3.49720150e-01 6.50279880e-01]\n",
      " [3.28299429e-05 9.99967217e-01]\n",
      " [3.17754916e-06 9.99996781e-01]\n",
      " [8.14454794e-01 1.85545266e-01]\n",
      " [7.98691213e-01 2.01308817e-01]\n",
      " [8.88827741e-01 1.11172207e-01]\n",
      " [1.07357801e-06 9.99998927e-01]\n",
      " [8.65054905e-01 1.34945095e-01]\n",
      " [4.96888220e-01 5.03111720e-01]\n",
      " [9.07233655e-01 9.27663296e-02]\n",
      " [4.30394560e-01 5.69605470e-01]\n",
      " [5.26976407e-01 4.73023593e-01]\n",
      " [5.50352693e-01 4.49647278e-01]\n",
      " [1.78484246e-04 9.99821484e-01]\n",
      " [8.78827989e-01 1.21172071e-01]\n",
      " [8.44789028e-01 1.55210927e-01]\n",
      " [1.09117282e-04 9.99890924e-01]\n",
      " [7.90062606e-01 2.09937468e-01]\n",
      " [5.96071362e-01 4.03928667e-01]\n",
      " [8.41929615e-01 1.58070371e-01]\n",
      " [5.09340644e-01 4.90659386e-01]\n",
      " [4.57370430e-01 5.42629540e-01]\n",
      " [8.39102805e-01 1.60897151e-01]\n",
      " [8.12935412e-01 1.87064603e-01]\n",
      " [2.43490323e-01 7.56509721e-01]\n",
      " [8.44050288e-01 1.55949771e-01]\n",
      " [7.14019060e-01 2.85980940e-01]\n",
      " [6.99889660e-01 3.00110310e-01]\n",
      " [3.92355770e-01 6.07644260e-01]\n",
      " [8.05697083e-01 1.94302887e-01]\n",
      " [6.62336767e-01 3.37663174e-01]\n",
      " [8.45827460e-01 1.54172525e-01]\n",
      " [2.00965405e-01 7.99034595e-01]\n",
      " [5.25371253e-01 4.74628747e-01]\n",
      " [1.59430513e-08 1.00000000e+00]\n",
      " [1.85496174e-04 9.99814570e-01]\n",
      " [7.71440744e-01 2.28559315e-01]\n",
      " [8.28661144e-01 1.71338856e-01]\n",
      " [8.90314758e-01 1.09685183e-01]\n",
      " [4.20231974e-11 1.00000000e+00]\n",
      " [9.08719718e-01 9.12802368e-02]\n",
      " [4.70064988e-04 9.99529958e-01]\n",
      " [9.08405483e-01 9.15944725e-02]\n",
      " [2.38726988e-01 7.61273086e-01]\n",
      " [8.22554231e-01 1.77445740e-01]\n",
      " [8.57675910e-01 1.42324075e-01]\n",
      " [8.13910246e-01 1.86089769e-01]\n",
      " [8.05460453e-01 1.94539577e-01]\n",
      " [9.17249680e-01 8.27502906e-02]\n",
      " [8.76444280e-01 1.23555630e-01]\n",
      " [8.04387152e-01 1.95612788e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(op)\n",
    "# for i in range(len(op)):\n",
    "#     op[i] = np.exp(op[i]) / np.sum(np.exp(op[i]))\n",
    "#op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 144/179\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(op)):\n",
    "    if labels_test[i][0] > labels_test[i][1]:\n",
    "        if op[i][0] > op[i][1]:\n",
    "            correct += 1\n",
    "    elif labels_test[i][0] < labels_test[i][1]:\n",
    "        if op[i][0] < op[i][1]:\n",
    "            correct += 1\n",
    "print(\"Acc: {}/{}\".format(correct, len(op)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_eval = w1.eval(session=sess)\n",
    "np.savetxt('w1.out', w1_eval, header=\"{},{}\".format(*w1_eval.shape), delimiter=\",\")\n",
    "\n",
    "w2_eval = w2.eval(session=sess)\n",
    "np.savetxt('w2.out', w2_eval, header=\"{},{}\".format(*w2_eval.shape), delimiter=\",\")\n",
    "\n",
    "wo_eval = wo.eval(session=sess)\n",
    "np.savetxt('wo.out', wo_eval, header=\"{},{}\".format(*wo_eval.shape), delimiter=\",\")\n",
    "\n",
    "b1_eval = b1.eval(session=sess)\n",
    "np.savetxt('b1.out', b1_eval, header=\"{},{}\".format(*b1_eval.shape), delimiter=\",\")\n",
    "\n",
    "b2_eval = b2.eval(session=sess)\n",
    "np.savetxt('b2.out', b2_eval, header=\"{},{}\".format(*b2_eval.shape), delimiter=\",\")\n",
    "\n",
    "bo_eval = bo.eval(session=sess)\n",
    "np.savetxt('bo.out', bo_eval, header=\"{},{}\".format(*bo_eval.shape), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w1.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('FF/input/test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all pre-processing steps as above\n",
    "df_test = df_test.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "df_test['Sex'] = df_test['Sex'].map({'female':0, 'male':1}).astype(int)\n",
    "df_test = pd.concat([df_test, pd.get_dummies(df_test['Embarked'], prefix='Embarked')], axis=1)\n",
    "df_test = df_test.drop('Embarked', axis=1)\n",
    "df_test['Age'] = (df_test['Age'] - age_mean) / age_std\n",
    "df_test['Fare'] = (df_test['Fare'] - fare_mean) / fare_std\n",
    "df_test.head()\n",
    "X_test = df_test.drop('PassengerId', axis=1).to_numpy()\n",
    "np.savetxt('test_unseen.out', X_test, header=\"{},{}\".format(*X_test.shape), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_test.shape[0]):\n",
    "    df_test.loc[i, 'Survived'] = sess.run(pred_label, feed_dict={inputs: X_test[i, None]}).squeeze()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame()\n",
    "output['PassengerId'] = df_test['PassengerId']\n",
    "output['Survived'] = df_test['Survived'].astype(int)\n",
    "output.to_csv('FF/output/prediction.csv', index=False)\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.savetxt('labels_test_seen.out', labels_test, header=\"{},{}\".format(*labels_test.shape), delimiter=\",\")\n",
    "labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
