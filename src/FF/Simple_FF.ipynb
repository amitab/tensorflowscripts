{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd        # For loading and processing the dataset\n",
    "import tensorflow as tf    # Of course, we need TensorFlow.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('input/train.csv')\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['PassengerId','Name','Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Sex'] = df_train['Sex'].map({'female':0, 'male':1}).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We replace 'Embarked' by three dummy variables 'Embarked_S', 'Embarked_C', and 'Embarked Q',\n",
    "# which are 1 if the person embarked there, and 0 otherwise.\n",
    "df_train = pd.concat([df_train, pd.get_dummies(df_train['Embarked'], prefix='Embarked')], axis=1)\n",
    "df_train = df_train.drop('Embarked', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We normalize the age and the fare by subtracting their mean and dividing by the standard deviation\n",
    "age_mean = df_train['Age'].mean()\n",
    "age_std = df_train['Age'].std()\n",
    "df_train['Age'] = (df_train['Age'] - age_mean) / age_std\n",
    "\n",
    "fare_mean = df_train['Fare'].mean()\n",
    "fare_std = df_train['Fare'].std()\n",
    "df_train['Fare'] = (df_train['Fare'] - fare_mean) / fare_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing 'Age' values: 177\n"
     ]
    }
   ],
   "source": [
    "# In many cases, the 'Age' is missing - which can cause problems. Let's look how bad it is:\n",
    "print(\"Number of missing 'Age' values: {:d}\".format(df_train['Age'].isnull().sum()))\n",
    "\n",
    "# A simple method to handle these missing values is to replace them by the mean age.\n",
    "df_train['Age'] = df_train['Age'].fillna(df_train['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.530005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.502163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.254646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.488580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364911</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364911</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex       Age  SibSp  Parch      Fare  Embarked_C  \\\n",
       "0         0       3    1 -0.530005      1      0 -0.502163           0   \n",
       "1         1       1    0  0.571430      1      0  0.786404           1   \n",
       "2         1       3    0 -0.254646      0      0 -0.488580           0   \n",
       "3         1       1    0  0.364911      1      0  0.420494           0   \n",
       "4         0       3    1  0.364911      0      0 -0.486064           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0           0           1  \n",
       "1           0           0  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           0           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we convert the Pandas dataframe to a NumPy array, and split it into a training and test set\n",
    "X_train = df_train.drop('Survived', axis=1).to_numpy()\n",
    "y_train = df_train['Survived'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "np.savetxt('test_seen.out', X_test, header=\"{},{}\".format(*X_test.shape), delimiter=\",\")\n",
    "np.savetxt('train.out', X_train, header=\"{},{}\".format(*X_train.shape), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll build a classifier with two classes: \"survived\" and \"didn't survive\",\n",
    "# so we create the according labels\n",
    "# This is taken from https://www.kaggle.com/klepacz/titanic/tensor-flow\n",
    "labels_train = (np.arange(2) == y_train[:,None]).astype(np.float32)\n",
    "labels_test = (np.arange(2) == y_test[:,None]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "inputs = tf.compat.v1.placeholder(tf.float32, shape=(None, X_train.shape[1]), name='inputs')\n",
    "label = tf.compat.v1.placeholder(tf.float32, shape=(None, 2), name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layer\n",
    "hid1_size = 128\n",
    "w1 = tf.Variable(tf.random.normal([hid1_size, X_train.shape[1]], stddev=0.01), name='w1')\n",
    "b1 = tf.Variable(tf.constant(0.1, shape=(hid1_size, 1)), name='b1')\n",
    "y1 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(w1, tf.transpose(a=inputs)), b1)), rate=1 - (0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second layer\n",
    "hid2_size = 256\n",
    "w2 = tf.Variable(tf.random.normal([hid2_size, hid1_size], stddev=0.01), name='w2')\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=(hid2_size, 1)), name='b2')\n",
    "y2 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(w2, y1), b2)), rate=1 - (0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "wo = tf.Variable(tf.random.normal([2, hid2_size], stddev=0.01), name='wo')\n",
    "bo = tf.Variable(tf.random.normal([2, 1]), name='bo')\n",
    "yo = tf.transpose(a=tf.add(tf.matmul(wo, y2), bo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "lr = tf.compat.v1.placeholder(tf.float32, shape=(), name='learning_rate')\n",
    "loss = tf.reduce_mean(input_tensor=tf.nn.softmax_cross_entropy_with_logits(logits=yo, labels=tf.stop_gradient(label)))\n",
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "pred = tf.nn.softmax(yo)\n",
    "pred_label = tf.argmax(input=pred, axis=1)\n",
    "correct_prediction = tf.equal(tf.argmax(input=pred, axis=1), tf.argmax(input=label, axis=1))\n",
    "accuracy = tf.reduce_mean(input_tensor=tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create operation which will initialize all variables\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "# Configure GPU not to use all memory\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Start a new tensorflow session and initialize variables\n",
    "sess = tf.compat.v1.InteractiveSession(config=config)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0    Train Cost: 0.6500\n",
      "Epoch:  10    Train Cost: 0.5304\n",
      "Epoch:  20    Train Cost: 0.5536\n",
      "Epoch:  30    Train Cost: 0.5345\n",
      "Epoch:  40    Train Cost: 0.5165\n",
      "Epoch:   0    Train Cost: 0.5328\n",
      "Epoch:  10    Train Cost: 0.4303\n",
      "Epoch:  20    Train Cost: 0.4102\n",
      "Epoch:  30    Train Cost: 0.4082\n",
      "Epoch:  40    Train Cost: 0.4046\n"
     ]
    }
   ],
   "source": [
    "writer = tf.compat.v1.summary.FileWriter('logs', sess.graph)\n",
    "\n",
    "# This is the main training loop: we train for 50 epochs with a learning rate of 0.05 and another \n",
    "# 50 epochs with a smaller learning rate of 0.01\n",
    "for learning_rate in [0.05, 0.01]:\n",
    "    for epoch in range(50):\n",
    "        avg_cost = 0.0\n",
    "\n",
    "        # For each epoch, we go through all the samples we have.\n",
    "        for i in range(X_train.shape[0]):\n",
    "            # Finally, this is where the magic happens: run our optimizer, feed the current example into X and the current target into Y\n",
    "            _, c = sess.run([optimizer, loss], feed_dict={lr:learning_rate, \n",
    "                                                          inputs: X_train[i, None],\n",
    "                                                          label: labels_train[i, None]})\n",
    "            avg_cost += c\n",
    "        avg_cost /= X_train.shape[0]    \n",
    "\n",
    "        # Print the cost in this epcho to the console.\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch: {:3d}    Train Cost: {:.4f}\".format(epoch, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 82.72%\n",
      "Test accuracy:  82.12%\n"
     ]
    }
   ],
   "source": [
    "acc_train = accuracy.eval(feed_dict={inputs: X_train, label: labels_train})\n",
    "print(\"Train accuracy: {:3.2f}%\".format(acc_train*100.0))\n",
    "acc_test = accuracy.eval(feed_dict={inputs: X_test, label: labels_test})\n",
    "print(\"Test accuracy:  {:3.2f}%\".format(acc_test*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'w1:0' shape=(128, 9) dtype=float32>,\n",
       " <tf.Variable 'b1:0' shape=(128, 1) dtype=float32>,\n",
       " <tf.Variable 'w2:0' shape=(256, 128) dtype=float32>,\n",
       " <tf.Variable 'b2:0' shape=(256, 1) dtype=float32>,\n",
       " <tf.Variable 'wo:0' shape=(2, 256) dtype=float32>,\n",
       " <tf.Variable 'bo:0' shape=(2, 1) dtype=float32>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars = tf.compat.v1.trainable_variables()\n",
    "vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_vals = sess.run(vars)\n",
    "np.savetxt('w1.out', vars_vals[0], header=\"{},{}\".format(*vars_vals[0].shape), delimiter=\",\")\n",
    "np.savetxt('b1.out', vars_vals[1], header=\"{},{}\".format(*vars_vals[1].shape), delimiter=\",\")\n",
    "np.savetxt('w2.out', vars_vals[2], header=\"{},{}\".format(*vars_vals[2].shape), delimiter=\",\")\n",
    "np.savetxt('b2.out', vars_vals[3], header=\"{},{}\".format(*vars_vals[3].shape), delimiter=\",\")\n",
    "np.savetxt('wo.out', vars_vals[4], header=\"{},{}\".format(*vars_vals[4].shape), delimiter=\",\")\n",
    "np.savetxt('bo.out', vars_vals[5], header=\"{},{}\".format(*vars_vals[5].shape), delimiter=\",\")\n",
    "np.savetxt('labels_test_seen.out', labels_test, header=\"{},{}\".format(*labels_test.shape), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = pred.eval(feed_dict={inputs: X_test})\n",
    "#op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.57930365e-03 9.93420660e-01]\n",
      " [8.49071622e-01 1.50928363e-01]\n",
      " [1.31089917e-06 9.99998689e-01]\n",
      " [8.86071742e-01 1.13928229e-01]\n",
      " [6.41204536e-01 3.58795464e-01]\n",
      " [8.77998710e-01 1.22001223e-01]\n",
      " [5.17407386e-03 9.94825900e-01]\n",
      " [8.79357040e-01 1.20642975e-01]\n",
      " [8.61778140e-01 1.38221875e-01]\n",
      " [8.79357040e-01 1.20642975e-01]\n",
      " [9.21191037e-01 7.88089707e-02]\n",
      " [8.80006313e-01 1.19993731e-01]\n",
      " [1.05196268e-05 9.99989510e-01]\n",
      " [2.90113302e-08 1.00000000e+00]\n",
      " [4.92710888e-01 5.07289052e-01]\n",
      " [3.48849177e-01 6.51150823e-01]\n",
      " [9.10336137e-01 8.96639228e-02]\n",
      " [9.95011091e-01 4.98895207e-03]\n",
      " [6.31387593e-05 9.99936819e-01]\n",
      " [5.85594535e-01 4.14405435e-01]\n",
      " [8.79357040e-01 1.20642975e-01]\n",
      " [3.28611851e-01 6.71388209e-01]\n",
      " [8.77361894e-01 1.22638054e-01]\n",
      " [7.36028767e-07 9.99999285e-01]\n",
      " [8.98243010e-01 1.01756990e-01]\n",
      " [7.18144834e-01 2.81855136e-01]\n",
      " [8.47544312e-01 1.52455673e-01]\n",
      " [3.34335983e-01 6.65664017e-01]\n",
      " [7.82088220e-01 2.17911720e-01]\n",
      " [8.86007011e-01 1.13993049e-01]\n",
      " [6.07266247e-01 3.92733842e-01]\n",
      " [4.86259758e-01 5.13740242e-01]\n",
      " [7.87424506e-06 9.99992132e-01]\n",
      " [8.93083751e-01 1.06916241e-01]\n",
      " [5.96390516e-02 9.40360904e-01]\n",
      " [7.58497596e-01 2.41502404e-01]\n",
      " [8.85447681e-01 1.14552334e-01]\n",
      " [8.53569448e-01 1.46430567e-01]\n",
      " [9.07637656e-01 9.23623592e-02]\n",
      " [6.12805068e-01 3.87194961e-01]\n",
      " [1.78649038e-01 8.21350992e-01]\n",
      " [8.89641345e-01 1.10358700e-01]\n",
      " [8.73654604e-01 1.26345351e-01]\n",
      " [8.78998578e-01 1.21001355e-01]\n",
      " [7.89495230e-01 2.10504711e-01]\n",
      " [8.80218089e-01 1.19781882e-01]\n",
      " [8.80527377e-01 1.19472593e-01]\n",
      " [9.37296093e-01 6.27038553e-02]\n",
      " [9.19565558e-01 8.04344639e-02]\n",
      " [8.65630805e-01 1.34369254e-01]\n",
      " [1.43333900e-05 9.99985695e-01]\n",
      " [8.18273187e-01 1.81726769e-01]\n",
      " [8.61924231e-01 1.38075754e-01]\n",
      " [4.91348028e-01 5.08651972e-01]\n",
      " [9.29427981e-01 7.05720484e-02]\n",
      " [7.69459784e-01 2.30540246e-01]\n",
      " [6.25094414e-01 3.74905556e-01]\n",
      " [8.88038337e-01 1.11961707e-01]\n",
      " [7.50483036e-01 2.49516949e-01]\n",
      " [8.93161654e-01 1.06838338e-01]\n",
      " [8.79357040e-01 1.20642975e-01]\n",
      " [3.14219574e-06 9.99996901e-01]\n",
      " [9.02951777e-01 9.70482752e-02]\n",
      " [7.35143244e-01 2.64856696e-01]\n",
      " [9.13348973e-01 8.66510123e-02]\n",
      " [8.79883051e-01 1.20116927e-01]\n",
      " [8.73431861e-01 1.26568198e-01]\n",
      " [8.79357040e-01 1.20642975e-01]\n",
      " [7.46610701e-01 2.53389269e-01]\n",
      " [5.81153181e-05 9.99941826e-01]\n",
      " [4.78954136e-01 5.21045864e-01]\n",
      " [9.01463985e-01 9.85360369e-02]\n",
      " [1.03702739e-01 8.96297216e-01]\n",
      " [8.88583720e-01 1.11416273e-01]\n",
      " [8.30509603e-01 1.69490427e-01]\n",
      " [7.31907666e-01 2.68092334e-01]\n",
      " [8.79357040e-01 1.20642975e-01]\n",
      " [6.12587452e-01 3.87412518e-01]\n",
      " [8.30889583e-01 1.69110373e-01]\n",
      " [7.99151003e-01 2.00849012e-01]\n",
      " [5.11948228e-01 4.88051713e-01]\n",
      " [6.29680574e-01 3.70319396e-01]\n",
      " [1.07201265e-06 9.99998927e-01]\n",
      " [2.82914788e-01 7.17085183e-01]\n",
      " [5.52794874e-01 4.47205096e-01]\n",
      " [8.77057076e-01 1.22942902e-01]\n",
      " [6.78260475e-02 9.32173908e-01]\n",
      " [8.52755785e-01 1.47244230e-01]\n",
      " [9.93388414e-01 6.61160843e-03]\n",
      " [4.74974930e-01 5.25025129e-01]\n",
      " [8.80274713e-01 1.19725265e-01]\n",
      " [2.07453072e-01 7.92546868e-01]\n",
      " [7.96689630e-01 2.03310415e-01]\n",
      " [7.93801308e-01 2.06198722e-01]\n",
      " [7.90058851e-01 2.09941104e-01]\n",
      " [6.58116400e-01 3.41883689e-01]\n",
      " [4.62932527e-01 5.37067473e-01]\n",
      " [5.74862480e-01 4.25137579e-01]\n",
      " [9.62488912e-03 9.90375102e-01]\n",
      " [7.74777532e-01 2.25222468e-01]\n",
      " [9.37793314e-01 6.22067153e-02]\n",
      " [8.56069505e-01 1.43930510e-01]\n",
      " [8.80933106e-01 1.19066946e-01]\n",
      " [8.88342738e-01 1.11657239e-01]\n",
      " [8.91962469e-01 1.08037598e-01]\n",
      " [8.79600763e-01 1.20399252e-01]\n",
      " [1.76050037e-01 8.23949933e-01]\n",
      " [7.97638357e-01 2.02361584e-01]\n",
      " [6.35162652e-01 3.64837348e-01]\n",
      " [6.93307817e-02 9.30669188e-01]\n",
      " [8.76807809e-01 1.23192161e-01]\n",
      " [1.26069619e-06 9.99998689e-01]\n",
      " [6.82926893e-01 3.17073077e-01]\n",
      " [8.70563865e-01 1.29436105e-01]\n",
      " [9.12892163e-01 8.71079043e-02]\n",
      " [8.84723902e-01 1.15276121e-01]\n",
      " [1.20040812e-02 9.87995923e-01]\n",
      " [8.81351292e-01 1.18648693e-01]\n",
      " [8.73077929e-01 1.26922101e-01]\n",
      " [8.87252927e-01 1.12747096e-01]\n",
      " [8.85103166e-01 1.14896804e-01]\n",
      " [7.96598673e-01 2.03401312e-01]\n",
      " [1.82309505e-02 9.81769085e-01]\n",
      " [8.07867765e-01 1.92132249e-01]\n",
      " [8.40975404e-01 1.59024596e-01]\n",
      " [8.72661769e-01 1.27338171e-01]\n",
      " [8.58018041e-01 1.41982004e-01]\n",
      " [3.33568230e-02 9.66643214e-01]\n",
      " [8.85581672e-01 1.14418298e-01]\n",
      " [3.49152565e-01 6.50847435e-01]\n",
      " [8.97612035e-01 1.02387942e-01]\n",
      " [8.79357040e-01 1.20642975e-01]\n",
      " [8.90639842e-01 1.09360196e-01]\n",
      " [8.74252260e-01 1.25747666e-01]\n",
      " [8.35664570e-01 1.64335489e-01]\n",
      " [5.05291462e-01 4.94708508e-01]\n",
      " [8.68647397e-01 1.31352633e-01]\n",
      " [3.39701116e-01 6.60298824e-01]\n",
      " [8.86674762e-01 1.13325231e-01]\n",
      " [8.00305934e-05 9.99920011e-01]\n",
      " [9.05825973e-01 9.41740647e-02]\n",
      " [8.57518852e-01 1.42481163e-01]\n",
      " [8.78032744e-01 1.21967249e-01]\n",
      " [7.67912924e-01 2.32087061e-01]\n",
      " [1.12602487e-01 8.87397528e-01]\n",
      " [4.27640706e-01 5.72359264e-01]\n",
      " [9.07767355e-01 9.22326669e-02]\n",
      " [7.28376925e-01 2.71623105e-01]\n",
      " [8.18694170e-05 9.99918103e-01]\n",
      " [8.94162297e-01 1.05837673e-01]\n",
      " [7.06604540e-01 2.93395430e-01]\n",
      " [7.11283565e-01 2.88716435e-01]\n",
      " [8.79357040e-01 1.20642975e-01]\n",
      " [8.11285555e-01 1.88714489e-01]\n",
      " [3.94741446e-01 6.05258524e-01]\n",
      " [8.93709183e-01 1.06290884e-01]\n",
      " [5.19650280e-01 4.80349779e-01]\n",
      " [9.57109571e-01 4.28903885e-02]\n",
      " [9.37738240e-01 6.22617155e-02]\n",
      " [8.29397023e-01 1.70602962e-01]\n",
      " [8.66529584e-01 1.33470431e-01]\n",
      " [9.02063429e-01 9.79365483e-02]\n",
      " [5.62545657e-01 4.37454283e-01]\n",
      " [9.83877659e-01 1.61222704e-02]\n",
      " [4.96088743e-01 5.03911197e-01]\n",
      " [8.18480849e-01 1.81519106e-01]\n",
      " [8.80374610e-01 1.19625412e-01]\n",
      " [9.75465834e-01 2.45341472e-02]\n",
      " [9.09410477e-01 9.05894414e-02]\n",
      " [8.83629739e-01 1.16370268e-01]\n",
      " [5.87965420e-04 9.99412060e-01]\n",
      " [8.63119304e-01 1.36880741e-01]\n",
      " [8.88428748e-01 1.11571319e-01]\n",
      " [9.06942606e-01 9.30573195e-02]\n",
      " [1.43356189e-01 8.56643796e-01]\n",
      " [8.74975026e-01 1.25024974e-01]\n",
      " [8.73190820e-01 1.26809180e-01]\n",
      " [2.23375797e-01 7.76624143e-01]\n",
      " [3.98594849e-02 9.60140586e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(op)\n",
    "# for i in range(len(op)):\n",
    "#     op[i] = np.exp(op[i]) / np.sum(np.exp(op[i]))\n",
    "#op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 146/179\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(op)):\n",
    "    if labels_test[i][0] > labels_test[i][1]:\n",
    "        if op[i][0] > op[i][1]:\n",
    "            correct += 1\n",
    "    elif labels_test[i][0] < labels_test[i][1]:\n",
    "        if op[i][0] < op[i][1]:\n",
    "            correct += 1\n",
    "print(\"Acc: {}/{}\".format(correct, len(op)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_eval = w1.eval(session=sess)\n",
    "np.savetxt('w1.out', w1_eval, header=\"{},{}\".format(*w1_eval.shape), delimiter=\",\")\n",
    "\n",
    "w2_eval = w2.eval(session=sess)\n",
    "np.savetxt('w2.out', w2_eval, header=\"{},{}\".format(*w2_eval.shape), delimiter=\",\")\n",
    "\n",
    "wo_eval = wo.eval(session=sess)\n",
    "np.savetxt('wo.out', wo_eval, header=\"{},{}\".format(*wo_eval.shape), delimiter=\",\")\n",
    "\n",
    "b1_eval = b1.eval(session=sess)\n",
    "np.savetxt('b1.out', b1_eval, header=\"{},{}\".format(*b1_eval.shape), delimiter=\",\")\n",
    "\n",
    "b2_eval = b2.eval(session=sess)\n",
    "np.savetxt('b2.out', b2_eval, header=\"{},{}\".format(*b2_eval.shape), delimiter=\",\")\n",
    "\n",
    "bo_eval = bo.eval(session=sess)\n",
    "np.savetxt('bo.out', bo_eval, header=\"{},{}\".format(*bo_eval.shape), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w1.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('input/test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all pre-processing steps as above\n",
    "df_test = df_test.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "df_test['Sex'] = df_test['Sex'].map({'female':0, 'male':1}).astype(int)\n",
    "df_test = pd.concat([df_test, pd.get_dummies(df_test['Embarked'], prefix='Embarked')], axis=1)\n",
    "df_test = df_test.drop('Embarked', axis=1)\n",
    "df_test['Age'] = (df_test['Age'] - age_mean) / age_std\n",
    "df_test['Fare'] = (df_test['Fare'] - fare_mean) / fare_std\n",
    "df_test.head()\n",
    "X_test = df_test.drop('PassengerId', axis=1).to_numpy()\n",
    "np.savetxt('test_unseen.out', X_test, header=\"{},{}\".format(*X_test.shape), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_test.shape[0]):\n",
    "    df_test.loc[i, 'Survived'] = sess.run(pred_label, feed_dict={inputs: X_test[i, None]}).squeeze()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame()\n",
    "output['PassengerId'] = df_test['PassengerId']\n",
    "output['Survived'] = df_test['Survived'].astype(int)\n",
    "output.to_csv('output/prediction.csv', index=False)\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.savetxt('labels_test_seen.out', labels_test, header=\"{},{}\".format(*labels_test.shape), delimiter=\",\")\n",
    "labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
